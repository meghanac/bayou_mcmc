0/10108000 (epoch 1) loss: 42.395, gen loss: 28.065, ret loss: 6.905, fp loss: 7.413, KL loss: 0.115. 
10000/10108000 (epoch 1) loss: 12.388, gen loss: 7.467, ret loss: 0.660, fp loss: 2.019, KL loss: 22.421. 
20000/10108000 (epoch 1) loss: 10.333, gen loss: 5.701, ret loss: 0.481, fp loss: 1.619, KL loss: 25.311. 
30000/10108000 (epoch 1) loss: 9.319, gen loss: 4.853, ret loss: 0.404, fp loss: 1.408, KL loss: 26.543. 
40000/10108000 (epoch 1) loss: 8.673, gen loss: 4.320, ret loss: 0.357, fp loss: 1.273, KL loss: 27.223. 
50000/10108000 (epoch 1) loss: 8.224, gen loss: 3.950, ret loss: 0.326, fp loss: 1.181, KL loss: 27.666. 
60000/10108000 (epoch 1) loss: 7.882, gen loss: 3.671, ret loss: 0.303, fp loss: 1.110, KL loss: 27.972. 
70000/10108000 (epoch 1) loss: 7.612, gen loss: 3.451, ret loss: 0.286, fp loss: 1.055, KL loss: 28.199. 
80000/10108000 (epoch 1) loss: 7.396, gen loss: 3.276, ret loss: 0.272, fp loss: 1.010, KL loss: 28.375. 
90000/10108000 (epoch 1) loss: 7.213, gen loss: 3.131, ret loss: 0.261, fp loss: 0.971, KL loss: 28.511. 
100000/10108000 (epoch 1) loss: 7.057, gen loss: 3.006, ret loss: 0.252, fp loss: 0.937, KL loss: 28.619. 
Model checkpoint: save/all_data_10k_vocab/model1.ckpt. Average for epoch , loss: 7.041
110000/10108000 (epoch 2) loss: 5.556, gen loss: 1.825, ret loss: 0.162, fp loss: 0.610, KL loss: 29.578. 
120000/10108000 (epoch 2) loss: 5.511, gen loss: 1.791, ret loss: 0.161, fp loss: 0.601, KL loss: 29.582. 
130000/10108000 (epoch 2) loss: 5.470, gen loss: 1.765, ret loss: 0.159, fp loss: 0.591, KL loss: 29.561. 
140000/10108000 (epoch 2) loss: 5.441, gen loss: 1.745, ret loss: 0.157, fp loss: 0.583, KL loss: 29.549. 
150000/10108000 (epoch 2) loss: 5.414, gen loss: 1.728, ret loss: 0.156, fp loss: 0.576, KL loss: 29.540. 
160000/10108000 (epoch 2) loss: 5.389, gen loss: 1.711, ret loss: 0.155, fp loss: 0.570, KL loss: 29.531. 
170000/10108000 (epoch 2) loss: 5.365, gen loss: 1.695, ret loss: 0.154, fp loss: 0.565, KL loss: 29.516. 
180000/10108000 (epoch 2) loss: 5.345, gen loss: 1.681, ret loss: 0.152, fp loss: 0.560, KL loss: 29.512. 
190000/10108000 (epoch 2) loss: 5.327, gen loss: 1.669, ret loss: 0.152, fp loss: 0.556, KL loss: 29.504. 
200000/10108000 (epoch 2) loss: 5.310, gen loss: 1.657, ret loss: 0.151, fp loss: 0.553, KL loss: 29.500. 
Model checkpoint: save/all_data_10k_vocab/model2.ckpt. Average for epoch , loss: 5.307
210000/10108000 (epoch 3) loss: 5.132, gen loss: 1.537, ret loss: 0.142, fp loss: 0.511, KL loss: 29.411. 
220000/10108000 (epoch 3) loss: 5.119, gen loss: 1.524, ret loss: 0.143, fp loss: 0.510, KL loss: 29.420. 
230000/10108000 (epoch 3) loss: 5.111, gen loss: 1.518, ret loss: 0.142, fp loss: 0.509, KL loss: 29.421. 
240000/10108000 (epoch 3) loss: 5.105, gen loss: 1.514, ret loss: 0.141, fp loss: 0.507, KL loss: 29.423. 
250000/10108000 (epoch 3) loss: 5.100, gen loss: 1.511, ret loss: 0.141, fp loss: 0.506, KL loss: 29.423. 
260000/10108000 (epoch 3) loss: 5.092, gen loss: 1.506, ret loss: 0.141, fp loss: 0.504, KL loss: 29.424. 
270000/10108000 (epoch 3) loss: 5.084, gen loss: 1.500, ret loss: 0.141, fp loss: 0.502, KL loss: 29.422. 
280000/10108000 (epoch 3) loss: 5.077, gen loss: 1.495, ret loss: 0.140, fp loss: 0.500, KL loss: 29.422. 
290000/10108000 (epoch 3) loss: 5.071, gen loss: 1.490, ret loss: 0.140, fp loss: 0.499, KL loss: 29.422. 
300000/10108000 (epoch 3) loss: 5.064, gen loss: 1.485, ret loss: 0.139, fp loss: 0.497, KL loss: 29.421. 
Model checkpoint: save/all_data_10k_vocab/model3.ckpt. Average for epoch , loss: 5.062
310000/10108000 (epoch 4) loss: 4.981, gen loss: 1.440, ret loss: 0.135, fp loss: 0.470, KL loss: 29.371. 
320000/10108000 (epoch 4) loss: 4.972, gen loss: 1.430, ret loss: 0.136, fp loss: 0.469, KL loss: 29.376. 
330000/10108000 (epoch 4) loss: 4.966, gen loss: 1.427, ret loss: 0.135, fp loss: 0.467, KL loss: 29.370. 
340000/10108000 (epoch 4) loss: 4.961, gen loss: 1.424, ret loss: 0.135, fp loss: 0.466, KL loss: 29.357. 
350000/10108000 (epoch 4) loss: 4.955, gen loss: 1.422, ret loss: 0.134, fp loss: 0.464, KL loss: 29.348. 
360000/10108000 (epoch 4) loss: 4.949, gen loss: 1.419, ret loss: 0.134, fp loss: 0.462, KL loss: 29.346. 
370000/10108000 (epoch 4) loss: 4.942, gen loss: 1.414, ret loss: 0.133, fp loss: 0.461, KL loss: 29.335. 
380000/10108000 (epoch 4) loss: 4.937, gen loss: 1.411, ret loss: 0.133, fp loss: 0.459, KL loss: 29.333. 
390000/10108000 (epoch 4) loss: 4.932, gen loss: 1.408, ret loss: 0.133, fp loss: 0.458, KL loss: 29.327. 
400000/10108000 (epoch 4) loss: 4.927, gen loss: 1.405, ret loss: 0.133, fp loss: 0.458, KL loss: 29.321. 
Model checkpoint: save/all_data_10k_vocab/model4.ckpt. Average for epoch , loss: 4.926
410000/10108000 (epoch 5) loss: 4.876, gen loss: 1.372, ret loss: 0.133, fp loss: 0.446, KL loss: 29.249. 
420000/10108000 (epoch 5) loss: 4.871, gen loss: 1.367, ret loss: 0.131, fp loss: 0.447, KL loss: 29.262. 
430000/10108000 (epoch 5) loss: 4.868, gen loss: 1.364, ret loss: 0.132, fp loss: 0.446, KL loss: 29.268. 
440000/10108000 (epoch 5) loss: 4.868, gen loss: 1.364, ret loss: 0.131, fp loss: 0.446, KL loss: 29.263. 
450000/10108000 (epoch 5) loss: 4.868, gen loss: 1.365, ret loss: 0.131, fp loss: 0.446, KL loss: 29.269. 
460000/10108000 (epoch 5) loss: 4.867, gen loss: 1.364, ret loss: 0.131, fp loss: 0.445, KL loss: 29.268. 
470000/10108000 (epoch 5) loss: 4.864, gen loss: 1.362, ret loss: 0.130, fp loss: 0.445, KL loss: 29.265. 
480000/10108000 (epoch 5) loss: 4.862, gen loss: 1.361, ret loss: 0.130, fp loss: 0.445, KL loss: 29.263. 
490000/10108000 (epoch 5) loss: 4.861, gen loss: 1.360, ret loss: 0.130, fp loss: 0.445, KL loss: 29.260. 
500000/10108000 (epoch 5) loss: 4.859, gen loss: 1.358, ret loss: 0.130, fp loss: 0.445, KL loss: 29.256. 
Model checkpoint: save/all_data_10k_vocab/model5.ckpt. Average for epoch , loss: 4.859
510000/10108000 (epoch 6) loss: 4.832, gen loss: 1.343, ret loss: 0.129, fp loss: 0.440, KL loss: 29.198. 
520000/10108000 (epoch 6) loss: 4.837, gen loss: 1.342, ret loss: 0.129, fp loss: 0.442, KL loss: 29.240. 
530000/10108000 (epoch 6) loss: 4.834, gen loss: 1.338, ret loss: 0.129, fp loss: 0.443, KL loss: 29.243. 
540000/10108000 (epoch 6) loss: 4.835, gen loss: 1.338, ret loss: 0.129, fp loss: 0.444, KL loss: 29.244. 
550000/10108000 (epoch 6) loss: 4.837, gen loss: 1.339, ret loss: 0.129, fp loss: 0.444, KL loss: 29.254. 
560000/10108000 (epoch 6) loss: 4.834, gen loss: 1.338, ret loss: 0.129, fp loss: 0.442, KL loss: 29.248. 
570000/10108000 (epoch 6) loss: 4.832, gen loss: 1.336, ret loss: 0.129, fp loss: 0.442, KL loss: 29.245. 
580000/10108000 (epoch 6) loss: 4.830, gen loss: 1.335, ret loss: 0.129, fp loss: 0.441, KL loss: 29.241. 
590000/10108000 (epoch 6) loss: 4.830, gen loss: 1.335, ret loss: 0.130, fp loss: 0.441, KL loss: 29.243. 
600000/10108000 (epoch 6) loss: 4.829, gen loss: 1.333, ret loss: 0.130, fp loss: 0.442, KL loss: 29.241. 
Model checkpoint: save/all_data_10k_vocab/model6.ckpt. Average for epoch , loss: 4.829
610000/10108000 (epoch 7) loss: 4.802, gen loss: 1.310, ret loss: 0.132, fp loss: 0.440, KL loss: 29.202. 
620000/10108000 (epoch 7) loss: 4.806, gen loss: 1.316, ret loss: 0.129, fp loss: 0.440, KL loss: 29.209. 
630000/10108000 (epoch 7) loss: 4.801, gen loss: 1.312, ret loss: 0.130, fp loss: 0.439, KL loss: 29.199. 
640000/10108000 (epoch 7) loss: 4.802, gen loss: 1.314, ret loss: 0.130, fp loss: 0.439, KL loss: 29.197. 
650000/10108000 (epoch 7) loss: 4.805, gen loss: 1.316, ret loss: 0.130, fp loss: 0.439, KL loss: 29.206. 
660000/10108000 (epoch 7) loss: 4.805, gen loss: 1.316, ret loss: 0.129, fp loss: 0.438, KL loss: 29.207. 
670000/10108000 (epoch 7) loss: 4.802, gen loss: 1.315, ret loss: 0.129, fp loss: 0.437, KL loss: 29.209. 
680000/10108000 (epoch 7) loss: 4.799, gen loss: 1.313, ret loss: 0.129, fp loss: 0.437, KL loss: 29.204. 
690000/10108000 (epoch 7) loss: 4.798, gen loss: 1.313, ret loss: 0.129, fp loss: 0.436, KL loss: 29.198. 
700000/10108000 (epoch 7) loss: 4.794, gen loss: 1.311, ret loss: 0.129, fp loss: 0.435, KL loss: 29.188. 
Model checkpoint: save/all_data_10k_vocab/model7.ckpt. Average for epoch , loss: 4.792
710000/10108000 (epoch 8) loss: 4.747, gen loss: 1.294, ret loss: 0.129, fp loss: 0.415, KL loss: 29.095. 
720000/10108000 (epoch 8) loss: 4.756, gen loss: 1.295, ret loss: 0.128, fp loss: 0.423, KL loss: 29.100. 
730000/10108000 (epoch 8) loss: 4.752, gen loss: 1.291, ret loss: 0.127, fp loss: 0.422, KL loss: 29.121. 
740000/10108000 (epoch 8) loss: 4.752, gen loss: 1.292, ret loss: 0.127, fp loss: 0.422, KL loss: 29.111. 
750000/10108000 (epoch 8) loss: 4.755, gen loss: 1.295, ret loss: 0.126, fp loss: 0.422, KL loss: 29.118. 
760000/10108000 (epoch 8) loss: 4.755, gen loss: 1.295, ret loss: 0.126, fp loss: 0.421, KL loss: 29.118. 
770000/10108000 (epoch 8) loss: 4.754, gen loss: 1.294, ret loss: 0.127, fp loss: 0.421, KL loss: 29.124. 
780000/10108000 (epoch 8) loss: 4.751, gen loss: 1.292, ret loss: 0.126, fp loss: 0.420, KL loss: 29.116. 
790000/10108000 (epoch 8) loss: 4.750, gen loss: 1.292, ret loss: 0.126, fp loss: 0.420, KL loss: 29.114. 
800000/10108000 (epoch 8) loss: 4.749, gen loss: 1.291, ret loss: 0.127, fp loss: 0.420, KL loss: 29.110. 
Model checkpoint: save/all_data_10k_vocab/model8.ckpt. Average for epoch , loss: 4.748
810000/10108000 (epoch 9) loss: 4.716, gen loss: 1.272, ret loss: 0.127, fp loss: 0.416, KL loss: 29.012. 
820000/10108000 (epoch 9) loss: 4.743, gen loss: 1.283, ret loss: 0.129, fp loss: 0.422, KL loss: 29.093. 
830000/10108000 (epoch 9) loss: 4.743, gen loss: 1.283, ret loss: 0.129, fp loss: 0.421, KL loss: 29.098. 
840000/10108000 (epoch 9) loss: 4.744, gen loss: 1.286, ret loss: 0.128, fp loss: 0.420, KL loss: 29.099. 
850000/10108000 (epoch 9) loss: 4.748, gen loss: 1.289, ret loss: 0.128, fp loss: 0.421, KL loss: 29.102. 
860000/10108000 (epoch 9) loss: 4.746, gen loss: 1.289, ret loss: 0.127, fp loss: 0.421, KL loss: 29.095. 
870000/10108000 (epoch 9) loss: 4.744, gen loss: 1.288, ret loss: 0.127, fp loss: 0.420, KL loss: 29.089. 
880000/10108000 (epoch 9) loss: 4.742, gen loss: 1.287, ret loss: 0.128, fp loss: 0.420, KL loss: 29.084. 
890000/10108000 (epoch 9) loss: 4.743, gen loss: 1.288, ret loss: 0.128, fp loss: 0.419, KL loss: 29.085. 
900000/10108000 (epoch 9) loss: 4.742, gen loss: 1.287, ret loss: 0.128, fp loss: 0.419, KL loss: 29.082. 
Model checkpoint: save/all_data_10k_vocab/model9.ckpt. Average for epoch , loss: 4.741
910000/10108000 (epoch 10) loss: 4.711, gen loss: 1.294, ret loss: 0.120, fp loss: 0.410, KL loss: 28.867. 
920000/10108000 (epoch 10) loss: 4.724, gen loss: 1.280, ret loss: 0.128, fp loss: 0.413, KL loss: 29.025. 
930000/10108000 (epoch 10) loss: 4.718, gen loss: 1.273, ret loss: 0.127, fp loss: 0.417, KL loss: 29.016. 
940000/10108000 (epoch 10) loss: 4.716, gen loss: 1.272, ret loss: 0.127, fp loss: 0.416, KL loss: 29.011. 
950000/10108000 (epoch 10) loss: 4.716, gen loss: 1.274, ret loss: 0.127, fp loss: 0.414, KL loss: 29.003. 
960000/10108000 (epoch 10) loss: 4.714, gen loss: 1.274, ret loss: 0.127, fp loss: 0.413, KL loss: 29.003. 
970000/10108000 (epoch 10) loss: 4.713, gen loss: 1.273, ret loss: 0.127, fp loss: 0.413, KL loss: 29.001. 
980000/10108000 (epoch 10) loss: 4.709, gen loss: 1.271, ret loss: 0.127, fp loss: 0.412, KL loss: 28.992. 
990000/10108000 (epoch 10) loss: 4.708, gen loss: 1.271, ret loss: 0.128, fp loss: 0.411, KL loss: 28.989. 
1000000/10108000 (epoch 10) loss: 4.707, gen loss: 1.271, ret loss: 0.128, fp loss: 0.410, KL loss: 28.988. 
1010000/10108000 (epoch 10) loss: 4.706, gen loss: 1.270, ret loss: 0.128, fp loss: 0.410, KL loss: 28.987. 
Model checkpoint: save/all_data_10k_vocab/model10.ckpt. Average for epoch , loss: 4.706
1020000/10108000 (epoch 11) loss: 4.693, gen loss: 1.272, ret loss: 0.127, fp loss: 0.400, KL loss: 28.945. 
1030000/10108000 (epoch 11) loss: 4.697, gen loss: 1.271, ret loss: 0.128, fp loss: 0.402, KL loss: 28.968. 
1040000/10108000 (epoch 11) loss: 4.695, gen loss: 1.269, ret loss: 0.129, fp loss: 0.401, KL loss: 28.967. 
1050000/10108000 (epoch 11) loss: 4.696, gen loss: 1.269, ret loss: 0.129, fp loss: 0.401, KL loss: 28.968. 
1060000/10108000 (epoch 11) loss: 4.695, gen loss: 1.270, ret loss: 0.129, fp loss: 0.400, KL loss: 28.961. 
1070000/10108000 (epoch 11) loss: 4.694, gen loss: 1.269, ret loss: 0.129, fp loss: 0.400, KL loss: 28.961. 
1080000/10108000 (epoch 11) loss: 4.691, gen loss: 1.267, ret loss: 0.129, fp loss: 0.400, KL loss: 28.956. 
1090000/10108000 (epoch 11) loss: 4.691, gen loss: 1.267, ret loss: 0.129, fp loss: 0.400, KL loss: 28.955. 
1100000/10108000 (epoch 11) loss: 4.692, gen loss: 1.267, ret loss: 0.129, fp loss: 0.399, KL loss: 28.957. 
1110000/10108000 (epoch 11) loss: 4.693, gen loss: 1.268, ret loss: 0.129, fp loss: 0.400, KL loss: 28.962. 
Model checkpoint: save/all_data_10k_vocab/model11.ckpt. Average for epoch , loss: 4.693
1120000/10108000 (epoch 12) loss: 4.699, gen loss: 1.269, ret loss: 0.130, fp loss: 0.404, KL loss: 28.955. 
1130000/10108000 (epoch 12) loss: 4.692, gen loss: 1.261, ret loss: 0.131, fp loss: 0.404, KL loss: 28.959. 
1140000/10108000 (epoch 12) loss: 4.690, gen loss: 1.261, ret loss: 0.131, fp loss: 0.404, KL loss: 28.946. 
1150000/10108000 (epoch 12) loss: 4.694, gen loss: 1.264, ret loss: 0.131, fp loss: 0.403, KL loss: 28.953. 
1160000/10108000 (epoch 12) loss: 4.696, gen loss: 1.266, ret loss: 0.130, fp loss: 0.404, KL loss: 28.957. 
1170000/10108000 (epoch 12) loss: 4.695, gen loss: 1.266, ret loss: 0.130, fp loss: 0.404, KL loss: 28.955. 
1180000/10108000 (epoch 12) loss: 4.692, gen loss: 1.264, ret loss: 0.130, fp loss: 0.403, KL loss: 28.945. 
1190000/10108000 (epoch 12) loss: 4.691, gen loss: 1.264, ret loss: 0.130, fp loss: 0.404, KL loss: 28.942. 
1200000/10108000 (epoch 12) loss: 4.693, gen loss: 1.264, ret loss: 0.130, fp loss: 0.405, KL loss: 28.943. 
1210000/10108000 (epoch 12) loss: 4.694, gen loss: 1.264, ret loss: 0.130, fp loss: 0.406, KL loss: 28.945. 
Model checkpoint: save/all_data_10k_vocab/model12.ckpt. Average for epoch , loss: 4.694
1220000/10108000 (epoch 13) loss: 4.704, gen loss: 1.268, ret loss: 0.127, fp loss: 0.411, KL loss: 28.988. 
1230000/10108000 (epoch 13) loss: 4.699, gen loss: 1.265, ret loss: 0.128, fp loss: 0.411, KL loss: 28.956. 
1240000/10108000 (epoch 13) loss: 4.696, gen loss: 1.264, ret loss: 0.128, fp loss: 0.409, KL loss: 28.952. 
1250000/10108000 (epoch 13) loss: 4.696, gen loss: 1.264, ret loss: 0.128, fp loss: 0.410, KL loss: 28.943. 
1260000/10108000 (epoch 13) loss: 4.698, gen loss: 1.265, ret loss: 0.129, fp loss: 0.410, KL loss: 28.937. 
1270000/10108000 (epoch 13) loss: 4.696, gen loss: 1.265, ret loss: 0.129, fp loss: 0.409, KL loss: 28.934. 
1280000/10108000 (epoch 13) loss: 4.694, gen loss: 1.264, ret loss: 0.129, fp loss: 0.408, KL loss: 28.928. 
1290000/10108000 (epoch 13) loss: 4.695, gen loss: 1.265, ret loss: 0.129, fp loss: 0.408, KL loss: 28.926. 
1300000/10108000 (epoch 13) loss: 4.696, gen loss: 1.266, ret loss: 0.129, fp loss: 0.408, KL loss: 28.926. 
1310000/10108000 (epoch 13) loss: 4.696, gen loss: 1.266, ret loss: 0.130, fp loss: 0.408, KL loss: 28.920. 
Model checkpoint: save/all_data_10k_vocab/model13.ckpt. Average for epoch , loss: 4.697
1320000/10108000 (epoch 14) loss: 4.692, gen loss: 1.263, ret loss: 0.134, fp loss: 0.407, KL loss: 28.882. 
1330000/10108000 (epoch 14) loss: 4.687, gen loss: 1.258, ret loss: 0.133, fp loss: 0.409, KL loss: 28.869. 
1340000/10108000 (epoch 14) loss: 4.691, gen loss: 1.262, ret loss: 0.133, fp loss: 0.409, KL loss: 28.868. 
1350000/10108000 (epoch 14) loss: 4.696, gen loss: 1.267, ret loss: 0.133, fp loss: 0.408, KL loss: 28.879. 
1360000/10108000 (epoch 14) loss: 4.698, gen loss: 1.268, ret loss: 0.133, fp loss: 0.408, KL loss: 28.888. 
1370000/10108000 (epoch 14) loss: 4.698, gen loss: 1.269, ret loss: 0.132, fp loss: 0.407, KL loss: 28.898. 
1380000/10108000 (epoch 14) loss: 4.696, gen loss: 1.268, ret loss: 0.132, fp loss: 0.407, KL loss: 28.892. 
1390000/10108000 (epoch 14) loss: 4.697, gen loss: 1.269, ret loss: 0.132, fp loss: 0.407, KL loss: 28.893. 
1400000/10108000 (epoch 14) loss: 4.698, gen loss: 1.270, ret loss: 0.132, fp loss: 0.408, KL loss: 28.893. 
1410000/10108000 (epoch 14) loss: 4.698, gen loss: 1.269, ret loss: 0.131, fp loss: 0.408, KL loss: 28.891. 
Model checkpoint: save/all_data_10k_vocab/model14.ckpt. Average for epoch , loss: 4.698
1420000/10108000 (epoch 15) loss: 4.693, gen loss: 1.266, ret loss: 0.133, fp loss: 0.410, KL loss: 28.841. 
1430000/10108000 (epoch 15) loss: 4.698, gen loss: 1.269, ret loss: 0.132, fp loss: 0.411, KL loss: 28.860. 
1440000/10108000 (epoch 15) loss: 4.697, gen loss: 1.267, ret loss: 0.131, fp loss: 0.412, KL loss: 28.864. 
1450000/10108000 (epoch 15) loss: 4.698, gen loss: 1.267, ret loss: 0.132, fp loss: 0.412, KL loss: 28.870. 
1460000/10108000 (epoch 15) loss: 4.701, gen loss: 1.269, ret loss: 0.132, fp loss: 0.413, KL loss: 28.881. 
1470000/10108000 (epoch 15) loss: 4.701, gen loss: 1.268, ret loss: 0.132, fp loss: 0.413, KL loss: 28.879. 
1480000/10108000 (epoch 15) loss: 4.700, gen loss: 1.268, ret loss: 0.131, fp loss: 0.413, KL loss: 28.881. 
1490000/10108000 (epoch 15) loss: 4.700, gen loss: 1.268, ret loss: 0.131, fp loss: 0.413, KL loss: 28.876. 
1500000/10108000 (epoch 15) loss: 4.701, gen loss: 1.269, ret loss: 0.131, fp loss: 0.413, KL loss: 28.877. 
1510000/10108000 (epoch 15) loss: 4.703, gen loss: 1.269, ret loss: 0.132, fp loss: 0.414, KL loss: 28.880. 
Model checkpoint: save/all_data_10k_vocab/model15.ckpt. Average for epoch , loss: 4.704
1520000/10108000 (epoch 16) loss: 4.705, gen loss: 1.271, ret loss: 0.131, fp loss: 0.411, KL loss: 28.925. 
1530000/10108000 (epoch 16) loss: 4.711, gen loss: 1.271, ret loss: 0.134, fp loss: 0.413, KL loss: 28.927. 
1540000/10108000 (epoch 16) loss: 4.703, gen loss: 1.264, ret loss: 0.133, fp loss: 0.413, KL loss: 28.923. 
1550000/10108000 (epoch 16) loss: 4.708, gen loss: 1.267, ret loss: 0.133, fp loss: 0.415, KL loss: 28.926. 
1560000/10108000 (epoch 16) loss: 4.712, gen loss: 1.269, ret loss: 0.133, fp loss: 0.417, KL loss: 28.928. 
1570000/10108000 (epoch 16) loss: 4.712, gen loss: 1.268, ret loss: 0.133, fp loss: 0.418, KL loss: 28.926. 
1580000/10108000 (epoch 16) loss: 4.709, gen loss: 1.267, ret loss: 0.133, fp loss: 0.417, KL loss: 28.922. 
1590000/10108000 (epoch 16) loss: 4.708, gen loss: 1.267, ret loss: 0.133, fp loss: 0.417, KL loss: 28.919. 
1600000/10108000 (epoch 16) loss: 4.709, gen loss: 1.267, ret loss: 0.132, fp loss: 0.417, KL loss: 28.920. 
1610000/10108000 (epoch 16) loss: 4.709, gen loss: 1.267, ret loss: 0.133, fp loss: 0.417, KL loss: 28.921. 
Model checkpoint: save/all_data_10k_vocab/model16.ckpt. Average for epoch , loss: 4.710
1620000/10108000 (epoch 17) loss: 4.713, gen loss: 1.258, ret loss: 0.134, fp loss: 0.431, KL loss: 28.896. 
1630000/10108000 (epoch 17) loss: 4.713, gen loss: 1.271, ret loss: 0.132, fp loss: 0.419, KL loss: 28.912. 
1640000/10108000 (epoch 17) loss: 4.713, gen loss: 1.273, ret loss: 0.131, fp loss: 0.418, KL loss: 28.915. 
1650000/10108000 (epoch 17) loss: 4.713, gen loss: 1.272, ret loss: 0.132, fp loss: 0.419, KL loss: 28.909. 
1660000/10108000 (epoch 17) loss: 4.719, gen loss: 1.275, ret loss: 0.132, fp loss: 0.420, KL loss: 28.919. 
1670000/10108000 (epoch 17) loss: 4.717, gen loss: 1.275, ret loss: 0.132, fp loss: 0.419, KL loss: 28.911. 
1680000/10108000 (epoch 17) loss: 4.716, gen loss: 1.273, ret loss: 0.133, fp loss: 0.419, KL loss: 28.912. 
1690000/10108000 (epoch 17) loss: 4.713, gen loss: 1.271, ret loss: 0.133, fp loss: 0.419, KL loss: 28.908. 
1700000/10108000 (epoch 17) loss: 4.713, gen loss: 1.271, ret loss: 0.133, fp loss: 0.418, KL loss: 28.907. 
1710000/10108000 (epoch 17) loss: 4.711, gen loss: 1.270, ret loss: 0.133, fp loss: 0.418, KL loss: 28.904. 
Model checkpoint: save/all_data_10k_vocab/model17.ckpt. Average for epoch , loss: 4.710
1720000/10108000 (epoch 18) loss: 4.709, gen loss: 1.274, ret loss: 0.132, fp loss: 0.410, KL loss: 28.924. 
1730000/10108000 (epoch 18) loss: 4.708, gen loss: 1.272, ret loss: 0.132, fp loss: 0.414, KL loss: 28.897. 
1740000/10108000 (epoch 18) loss: 4.709, gen loss: 1.269, ret loss: 0.133, fp loss: 0.416, KL loss: 28.906. 
1750000/10108000 (epoch 18) loss: 4.711, gen loss: 1.273, ret loss: 0.133, fp loss: 0.414, KL loss: 28.904. 
1760000/10108000 (epoch 18) loss: 4.713, gen loss: 1.274, ret loss: 0.134, fp loss: 0.415, KL loss: 28.902. 
1770000/10108000 (epoch 18) loss: 4.716, gen loss: 1.273, ret loss: 0.134, fp loss: 0.417, KL loss: 28.913. 
1780000/10108000 (epoch 18) loss: 4.716, gen loss: 1.274, ret loss: 0.134, fp loss: 0.417, KL loss: 28.913. 
1790000/10108000 (epoch 18) loss: 4.716, gen loss: 1.274, ret loss: 0.134, fp loss: 0.418, KL loss: 28.906. 
1800000/10108000 (epoch 18) loss: 4.717, gen loss: 1.274, ret loss: 0.134, fp loss: 0.419, KL loss: 28.909. 
1810000/10108000 (epoch 18) loss: 4.719, gen loss: 1.275, ret loss: 0.133, fp loss: 0.420, KL loss: 28.907. 
Model checkpoint: save/all_data_10k_vocab/model18.ckpt. Average for epoch , loss: 4.719
1820000/10108000 (epoch 19) loss: 4.678, gen loss: 1.238, ret loss: 0.148, fp loss: 0.416, KL loss: 28.759. 
1830000/10108000 (epoch 19) loss: 4.706, gen loss: 1.260, ret loss: 0.136, fp loss: 0.423, KL loss: 28.880. 
1840000/10108000 (epoch 19) loss: 4.705, gen loss: 1.256, ret loss: 0.135, fp loss: 0.426, KL loss: 28.877. 
1850000/10108000 (epoch 19) loss: 4.704, gen loss: 1.257, ret loss: 0.135, fp loss: 0.426, KL loss: 28.868. 
1860000/10108000 (epoch 19) loss: 4.707, gen loss: 1.259, ret loss: 0.134, fp loss: 0.426, KL loss: 28.878. 
1870000/10108000 (epoch 19) loss: 4.711, gen loss: 1.262, ret loss: 0.135, fp loss: 0.427, KL loss: 28.879. 
1880000/10108000 (epoch 19) loss: 4.711, gen loss: 1.263, ret loss: 0.135, fp loss: 0.426, KL loss: 28.879. 
1890000/10108000 (epoch 19) loss: 4.709, gen loss: 1.262, ret loss: 0.134, fp loss: 0.425, KL loss: 28.880. 
1900000/10108000 (epoch 19) loss: 4.708, gen loss: 1.263, ret loss: 0.134, fp loss: 0.424, KL loss: 28.875. 
1910000/10108000 (epoch 19) loss: 4.710, gen loss: 1.264, ret loss: 0.134, fp loss: 0.424, KL loss: 28.877. 
1920000/10108000 (epoch 19) loss: 4.711, gen loss: 1.265, ret loss: 0.134, fp loss: 0.424, KL loss: 28.879. 
Model checkpoint: save/all_data_10k_vocab/model19.ckpt. Average for epoch , loss: 4.711
1930000/10108000 (epoch 20) loss: 4.701, gen loss: 1.255, ret loss: 0.137, fp loss: 0.422, KL loss: 28.871. 
1940000/10108000 (epoch 20) loss: 4.709, gen loss: 1.256, ret loss: 0.136, fp loss: 0.428, KL loss: 28.889. 
1950000/10108000 (epoch 20) loss: 4.711, gen loss: 1.257, ret loss: 0.135, fp loss: 0.430, KL loss: 28.893. 
1960000/10108000 (epoch 20) loss: 4.715, gen loss: 1.260, ret loss: 0.135, fp loss: 0.431, KL loss: 28.897. 
1970000/10108000 (epoch 20) loss: 4.717, gen loss: 1.261, ret loss: 0.135, fp loss: 0.431, KL loss: 28.893. 
1980000/10108000 (epoch 20) loss: 4.716, gen loss: 1.260, ret loss: 0.135, fp loss: 0.431, KL loss: 28.887. 
1990000/10108000 (epoch 20) loss: 4.716, gen loss: 1.261, ret loss: 0.135, fp loss: 0.431, KL loss: 28.886. 
2000000/10108000 (epoch 20) loss: 4.716, gen loss: 1.262, ret loss: 0.135, fp loss: 0.431, KL loss: 28.881. 
2010000/10108000 (epoch 20) loss: 4.716, gen loss: 1.264, ret loss: 0.135, fp loss: 0.431, KL loss: 28.872. 
2020000/10108000 (epoch 20) loss: 4.717, gen loss: 1.264, ret loss: 0.135, fp loss: 0.431, KL loss: 28.873. 
Model checkpoint: save/all_data_10k_vocab/model20.ckpt. Average for epoch , loss: 4.717
2030000/10108000 (epoch 21) loss: 4.719, gen loss: 1.273, ret loss: 0.134, fp loss: 0.428, KL loss: 28.844. 
2040000/10108000 (epoch 21) loss: 4.719, gen loss: 1.268, ret loss: 0.134, fp loss: 0.430, KL loss: 28.871. 
2050000/10108000 (epoch 21) loss: 4.716, gen loss: 1.264, ret loss: 0.134, fp loss: 0.430, KL loss: 28.869. 
2060000/10108000 (epoch 21) loss: 4.717, gen loss: 1.267, ret loss: 0.134, fp loss: 0.429, KL loss: 28.871. 
2070000/10108000 (epoch 21) loss: 4.720, gen loss: 1.269, ret loss: 0.134, fp loss: 0.429, KL loss: 28.876. 
2080000/10108000 (epoch 21) loss: 4.720, gen loss: 1.269, ret loss: 0.134, fp loss: 0.429, KL loss: 28.883. 
2090000/10108000 (epoch 21) loss: 4.717, gen loss: 1.267, ret loss: 0.134, fp loss: 0.428, KL loss: 28.876. 
2100000/10108000 (epoch 21) loss: 4.715, gen loss: 1.266, ret loss: 0.134, fp loss: 0.428, KL loss: 28.872. 
2110000/10108000 (epoch 21) loss: 4.714, gen loss: 1.266, ret loss: 0.134, fp loss: 0.427, KL loss: 28.868. 
2120000/10108000 (epoch 21) loss: 4.715, gen loss: 1.266, ret loss: 0.134, fp loss: 0.428, KL loss: 28.868. 
Model checkpoint: save/all_data_10k_vocab/model21.ckpt. Average for epoch , loss: 4.714
2130000/10108000 (epoch 22) loss: 4.710, gen loss: 1.273, ret loss: 0.136, fp loss: 0.419, KL loss: 28.822. 
2140000/10108000 (epoch 22) loss: 4.705, gen loss: 1.261, ret loss: 0.137, fp loss: 0.423, KL loss: 28.839. 
2150000/10108000 (epoch 22) loss: 4.707, gen loss: 1.261, ret loss: 0.137, fp loss: 0.425, KL loss: 28.838. 
2160000/10108000 (epoch 22) loss: 4.706, gen loss: 1.263, ret loss: 0.136, fp loss: 0.423, KL loss: 28.839. 
2170000/10108000 (epoch 22) loss: 4.706, gen loss: 1.264, ret loss: 0.136, fp loss: 0.422, KL loss: 28.847. 
2180000/10108000 (epoch 22) loss: 4.708, gen loss: 1.266, ret loss: 0.136, fp loss: 0.421, KL loss: 28.856. 
2190000/10108000 (epoch 22) loss: 4.705, gen loss: 1.265, ret loss: 0.135, fp loss: 0.421, KL loss: 28.853. 
2200000/10108000 (epoch 22) loss: 4.703, gen loss: 1.265, ret loss: 0.135, fp loss: 0.419, KL loss: 28.845. 
2210000/10108000 (epoch 22) loss: 4.703, gen loss: 1.266, ret loss: 0.135, fp loss: 0.418, KL loss: 28.842. 
2220000/10108000 (epoch 22) loss: 4.702, gen loss: 1.265, ret loss: 0.135, fp loss: 0.419, KL loss: 28.840. 
Model checkpoint: save/all_data_10k_vocab/model22.ckpt. Average for epoch , loss: 4.702
2230000/10108000 (epoch 23) loss: 4.696, gen loss: 1.262, ret loss: 0.135, fp loss: 0.416, KL loss: 28.824. 
2240000/10108000 (epoch 23) loss: 4.686, gen loss: 1.254, ret loss: 0.133, fp loss: 0.417, KL loss: 28.818. 
2250000/10108000 (epoch 23) loss: 4.687, gen loss: 1.254, ret loss: 0.133, fp loss: 0.418, KL loss: 28.821. 
2260000/10108000 (epoch 23) loss: 4.689, gen loss: 1.256, ret loss: 0.134, fp loss: 0.417, KL loss: 28.813. 
2270000/10108000 (epoch 23) loss: 4.692, gen loss: 1.258, ret loss: 0.134, fp loss: 0.418, KL loss: 28.815. 
2280000/10108000 (epoch 23) loss: 4.692, gen loss: 1.260, ret loss: 0.134, fp loss: 0.417, KL loss: 28.815. 
2290000/10108000 (epoch 23) loss: 4.690, gen loss: 1.258, ret loss: 0.134, fp loss: 0.417, KL loss: 28.811. 
2300000/10108000 (epoch 23) loss: 4.691, gen loss: 1.260, ret loss: 0.134, fp loss: 0.416, KL loss: 28.807. 
2310000/10108000 (epoch 23) loss: 4.691, gen loss: 1.261, ret loss: 0.134, fp loss: 0.416, KL loss: 28.804. 
2320000/10108000 (epoch 23) loss: 4.691, gen loss: 1.260, ret loss: 0.135, fp loss: 0.416, KL loss: 28.802. 
Model checkpoint: save/all_data_10k_vocab/model23.ckpt. Average for epoch , loss: 4.691
2330000/10108000 (epoch 24) loss: 4.690, gen loss: 1.268, ret loss: 0.135, fp loss: 0.411, KL loss: 28.762. 
2340000/10108000 (epoch 24) loss: 4.702, gen loss: 1.268, ret loss: 0.137, fp loss: 0.416, KL loss: 28.801. 
2350000/10108000 (epoch 24) loss: 4.704, gen loss: 1.269, ret loss: 0.137, fp loss: 0.417, KL loss: 28.816. 
2360000/10108000 (epoch 24) loss: 4.704, gen loss: 1.269, ret loss: 0.136, fp loss: 0.418, KL loss: 28.813. 
2370000/10108000 (epoch 24) loss: 4.707, gen loss: 1.271, ret loss: 0.136, fp loss: 0.419, KL loss: 28.814. 
2380000/10108000 (epoch 24) loss: 4.710, gen loss: 1.274, ret loss: 0.135, fp loss: 0.420, KL loss: 28.816. 
2390000/10108000 (epoch 24) loss: 4.713, gen loss: 1.276, ret loss: 0.135, fp loss: 0.421, KL loss: 28.819. 
2400000/10108000 (epoch 24) loss: 4.715, gen loss: 1.277, ret loss: 0.134, fp loss: 0.422, KL loss: 28.823. 
2410000/10108000 (epoch 24) loss: 4.716, gen loss: 1.279, ret loss: 0.134, fp loss: 0.421, KL loss: 28.826. 
2420000/10108000 (epoch 24) loss: 4.717, gen loss: 1.280, ret loss: 0.134, fp loss: 0.420, KL loss: 28.825. 
Model checkpoint: save/all_data_10k_vocab/model24.ckpt. Average for epoch , loss: 4.717
2430000/10108000 (epoch 25) loss: 4.719, gen loss: 1.287, ret loss: 0.134, fp loss: 0.415, KL loss: 28.833. 
2440000/10108000 (epoch 25) loss: 4.716, gen loss: 1.286, ret loss: 0.132, fp loss: 0.416, KL loss: 28.814. 
2450000/10108000 (epoch 25) loss: 4.719, gen loss: 1.287, ret loss: 0.131, fp loss: 0.418, KL loss: 28.829. 
2460000/10108000 (epoch 25) loss: 4.719, gen loss: 1.287, ret loss: 0.132, fp loss: 0.419, KL loss: 28.820. 
2470000/10108000 (epoch 25) loss: 4.720, gen loss: 1.289, ret loss: 0.132, fp loss: 0.417, KL loss: 28.816. 
2480000/10108000 (epoch 25) loss: 4.718, gen loss: 1.288, ret loss: 0.132, fp loss: 0.416, KL loss: 28.814. 
2490000/10108000 (epoch 25) loss: 4.713, gen loss: 1.286, ret loss: 0.132, fp loss: 0.415, KL loss: 28.806. 
2500000/10108000 (epoch 25) loss: 4.710, gen loss: 1.283, ret loss: 0.132, fp loss: 0.414, KL loss: 28.804. 
2510000/10108000 (epoch 25) loss: 4.710, gen loss: 1.283, ret loss: 0.133, fp loss: 0.415, KL loss: 28.804. 
2520000/10108000 (epoch 25) loss: 4.712, gen loss: 1.283, ret loss: 0.133, fp loss: 0.415, KL loss: 28.802. 
Model checkpoint: save/all_data_10k_vocab/model25.ckpt. Average for epoch , loss: 4.712
2530000/10108000 (epoch 26) loss: 4.698, gen loss: 1.269, ret loss: 0.136, fp loss: 0.415, KL loss: 28.793. 
2540000/10108000 (epoch 26) loss: 4.722, gen loss: 1.288, ret loss: 0.135, fp loss: 0.418, KL loss: 28.810. 
2550000/10108000 (epoch 26) loss: 4.723, gen loss: 1.288, ret loss: 0.133, fp loss: 0.419, KL loss: 28.824. 
2560000/10108000 (epoch 26) loss: 4.724, gen loss: 1.288, ret loss: 0.133, fp loss: 0.420, KL loss: 28.824. 
2570000/10108000 (epoch 26) loss: 4.724, gen loss: 1.289, ret loss: 0.133, fp loss: 0.420, KL loss: 28.819. 
2580000/10108000 (epoch 26) loss: 4.722, gen loss: 1.287, ret loss: 0.134, fp loss: 0.420, KL loss: 28.817. 
2590000/10108000 (epoch 26) loss: 4.721, gen loss: 1.286, ret loss: 0.134, fp loss: 0.419, KL loss: 28.819. 
2600000/10108000 (epoch 26) loss: 4.721, gen loss: 1.286, ret loss: 0.134, fp loss: 0.419, KL loss: 28.820. 
2610000/10108000 (epoch 26) loss: 4.720, gen loss: 1.287, ret loss: 0.134, fp loss: 0.418, KL loss: 28.820. 
2620000/10108000 (epoch 26) loss: 4.720, gen loss: 1.286, ret loss: 0.134, fp loss: 0.418, KL loss: 28.820. 
Model checkpoint: save/all_data_10k_vocab/model26.ckpt. Average for epoch , loss: 4.719
2630000/10108000 (epoch 27) loss: 4.712, gen loss: 1.286, ret loss: 0.134, fp loss: 0.411, KL loss: 28.802. 
2640000/10108000 (epoch 27) loss: 4.707, gen loss: 1.280, ret loss: 0.136, fp loss: 0.414, KL loss: 28.772. 
2650000/10108000 (epoch 27) loss: 4.698, gen loss: 1.268, ret loss: 0.135, fp loss: 0.418, KL loss: 28.774. 
2660000/10108000 (epoch 27) loss: 4.703, gen loss: 1.271, ret loss: 0.135, fp loss: 0.418, KL loss: 28.786. 
2670000/10108000 (epoch 27) loss: 4.711, gen loss: 1.279, ret loss: 0.134, fp loss: 0.419, KL loss: 28.794. 
2680000/10108000 (epoch 27) loss: 4.714, gen loss: 1.279, ret loss: 0.135, fp loss: 0.420, KL loss: 28.802. 
2690000/10108000 (epoch 27) loss: 4.713, gen loss: 1.278, ret loss: 0.135, fp loss: 0.420, KL loss: 28.807. 
2700000/10108000 (epoch 27) loss: 4.712, gen loss: 1.277, ret loss: 0.135, fp loss: 0.420, KL loss: 28.803. 
2710000/10108000 (epoch 27) loss: 4.714, gen loss: 1.278, ret loss: 0.134, fp loss: 0.421, KL loss: 28.805. 
2720000/10108000 (epoch 27) loss: 4.714, gen loss: 1.278, ret loss: 0.135, fp loss: 0.421, KL loss: 28.806. 
Model checkpoint: save/all_data_10k_vocab/model27.ckpt. Average for epoch , loss: 4.713
2730000/10108000 (epoch 28) loss: 4.641, gen loss: 1.234, ret loss: 0.142, fp loss: 0.411, KL loss: 28.544. 
2740000/10108000 (epoch 28) loss: 4.703, gen loss: 1.266, ret loss: 0.136, fp loss: 0.423, KL loss: 28.785. 
2750000/10108000 (epoch 28) loss: 4.711, gen loss: 1.262, ret loss: 0.136, fp loss: 0.431, KL loss: 28.825. 
2760000/10108000 (epoch 28) loss: 4.714, gen loss: 1.264, ret loss: 0.136, fp loss: 0.431, KL loss: 28.834. 
2770000/10108000 (epoch 28) loss: 4.717, gen loss: 1.266, ret loss: 0.136, fp loss: 0.432, KL loss: 28.833. 
2780000/10108000 (epoch 28) loss: 4.721, gen loss: 1.267, ret loss: 0.136, fp loss: 0.434, KL loss: 28.832. 
2790000/10108000 (epoch 28) loss: 4.719, gen loss: 1.268, ret loss: 0.136, fp loss: 0.433, KL loss: 28.828. 
2800000/10108000 (epoch 28) loss: 4.715, gen loss: 1.267, ret loss: 0.136, fp loss: 0.430, KL loss: 28.816. 
2810000/10108000 (epoch 28) loss: 4.714, gen loss: 1.267, ret loss: 0.136, fp loss: 0.429, KL loss: 28.813. 
2820000/10108000 (epoch 28) loss: 4.713, gen loss: 1.267, ret loss: 0.136, fp loss: 0.429, KL loss: 28.811. 
2830000/10108000 (epoch 28) loss: 4.714, gen loss: 1.268, ret loss: 0.136, fp loss: 0.429, KL loss: 28.814. 
Model checkpoint: save/all_data_10k_vocab/model28.ckpt. Average for epoch , loss: 4.714
2840000/10108000 (epoch 29) loss: 4.716, gen loss: 1.273, ret loss: 0.139, fp loss: 0.426, KL loss: 28.783. 
2850000/10108000 (epoch 29) loss: 4.714, gen loss: 1.278, ret loss: 0.136, fp loss: 0.424, KL loss: 28.759. 
2860000/10108000 (epoch 29) loss: 4.712, gen loss: 1.278, ret loss: 0.136, fp loss: 0.423, KL loss: 28.751. 
2870000/10108000 (epoch 29) loss: 4.716, gen loss: 1.280, ret loss: 0.136, fp loss: 0.423, KL loss: 28.766. 
2880000/10108000 (epoch 29) loss: 4.717, gen loss: 1.282, ret loss: 0.135, fp loss: 0.423, KL loss: 28.773. 
2890000/10108000 (epoch 29) loss: 4.718, gen loss: 1.282, ret loss: 0.135, fp loss: 0.422, KL loss: 28.785. 
2900000/10108000 (epoch 29) loss: 4.717, gen loss: 1.281, ret loss: 0.135, fp loss: 0.422, KL loss: 28.787. 
2910000/10108000 (epoch 29) loss: 4.720, gen loss: 1.282, ret loss: 0.136, fp loss: 0.423, KL loss: 28.792. 
2920000/10108000 (epoch 29) loss: 4.721, gen loss: 1.282, ret loss: 0.136, fp loss: 0.423, KL loss: 28.791. 
2930000/10108000 (epoch 29) loss: 4.722, gen loss: 1.283, ret loss: 0.136, fp loss: 0.424, KL loss: 28.794. 
Model checkpoint: save/all_data_10k_vocab/model29.ckpt. Average for epoch , loss: 4.723
2940000/10108000 (epoch 30) loss: 4.730, gen loss: 1.292, ret loss: 0.137, fp loss: 0.420, KL loss: 28.808. 
2950000/10108000 (epoch 30) loss: 4.716, gen loss: 1.276, ret loss: 0.137, fp loss: 0.422, KL loss: 28.806. 
2960000/10108000 (epoch 30) loss: 4.712, gen loss: 1.272, ret loss: 0.137, fp loss: 0.423, KL loss: 28.800. 
2970000/10108000 (epoch 30) loss: 4.722, gen loss: 1.277, ret loss: 0.137, fp loss: 0.426, KL loss: 28.825. 
2980000/10108000 (epoch 30) loss: 4.725, gen loss: 1.280, ret loss: 0.137, fp loss: 0.426, KL loss: 28.826. 
2990000/10108000 (epoch 30) loss: 4.726, gen loss: 1.282, ret loss: 0.137, fp loss: 0.426, KL loss: 28.822. 
3000000/10108000 (epoch 30) loss: 4.728, gen loss: 1.281, ret loss: 0.137, fp loss: 0.426, KL loss: 28.829. 
3010000/10108000 (epoch 30) loss: 4.732, gen loss: 1.283, ret loss: 0.137, fp loss: 0.428, KL loss: 28.837. 
3020000/10108000 (epoch 30) loss: 4.732, gen loss: 1.284, ret loss: 0.137, fp loss: 0.429, KL loss: 28.828. 
3030000/10108000 (epoch 30) loss: 4.732, gen loss: 1.284, ret loss: 0.137, fp loss: 0.429, KL loss: 28.827. 
Model checkpoint: save/all_data_10k_vocab/model30.ckpt. Average for epoch , loss: 4.732
3040000/10108000 (epoch 31) loss: 4.767, gen loss: 1.301, ret loss: 0.138, fp loss: 0.442, KL loss: 28.857. 
3050000/10108000 (epoch 31) loss: 4.755, gen loss: 1.300, ret loss: 0.136, fp loss: 0.438, KL loss: 28.811. 
3060000/10108000 (epoch 31) loss: 4.751, gen loss: 1.300, ret loss: 0.135, fp loss: 0.435, KL loss: 28.809. 
3070000/10108000 (epoch 31) loss: 4.753, gen loss: 1.301, ret loss: 0.136, fp loss: 0.435, KL loss: 28.810. 
3080000/10108000 (epoch 31) loss: 4.753, gen loss: 1.301, ret loss: 0.136, fp loss: 0.435, KL loss: 28.810. 
3090000/10108000 (epoch 31) loss: 4.753, gen loss: 1.303, ret loss: 0.135, fp loss: 0.434, KL loss: 28.811. 
3100000/10108000 (epoch 31) loss: 4.750, gen loss: 1.302, ret loss: 0.135, fp loss: 0.433, KL loss: 28.802. 
3110000/10108000 (epoch 31) loss: 4.749, gen loss: 1.301, ret loss: 0.135, fp loss: 0.432, KL loss: 28.802. 
3120000/10108000 (epoch 31) loss: 4.748, gen loss: 1.300, ret loss: 0.135, fp loss: 0.433, KL loss: 28.802. 
3130000/10108000 (epoch 31) loss: 4.748, gen loss: 1.299, ret loss: 0.135, fp loss: 0.433, KL loss: 28.806. 
Model checkpoint: save/all_data_10k_vocab/model31.ckpt. Average for epoch , loss: 4.748
3140000/10108000 (epoch 32) loss: 4.748, gen loss: 1.302, ret loss: 0.136, fp loss: 0.431, KL loss: 28.787. 
3150000/10108000 (epoch 32) loss: 4.747, gen loss: 1.297, ret loss: 0.134, fp loss: 0.433, KL loss: 28.817. 
3160000/10108000 (epoch 32) loss: 4.745, gen loss: 1.295, ret loss: 0.134, fp loss: 0.434, KL loss: 28.817. 
3170000/10108000 (epoch 32) loss: 4.751, gen loss: 1.299, ret loss: 0.134, fp loss: 0.434, KL loss: 28.829. 
3180000/10108000 (epoch 32) loss: 4.751, gen loss: 1.299, ret loss: 0.135, fp loss: 0.435, KL loss: 28.830. 
3190000/10108000 (epoch 32) loss: 4.751, gen loss: 1.299, ret loss: 0.135, fp loss: 0.435, KL loss: 28.834. 
3200000/10108000 (epoch 32) loss: 4.750, gen loss: 1.298, ret loss: 0.135, fp loss: 0.434, KL loss: 28.830. 
3210000/10108000 (epoch 32) loss: 4.753, gen loss: 1.300, ret loss: 0.134, fp loss: 0.435, KL loss: 28.834. 
3220000/10108000 (epoch 32) loss: 4.754, gen loss: 1.301, ret loss: 0.134, fp loss: 0.435, KL loss: 28.832. 
3230000/10108000 (epoch 32) loss: 4.756, gen loss: 1.302, ret loss: 0.135, fp loss: 0.436, KL loss: 28.836. 
Model checkpoint: save/all_data_10k_vocab/model32.ckpt. Average for epoch , loss: 4.758
3240000/10108000 (epoch 33) loss: 4.832, gen loss: 1.336, ret loss: 0.138, fp loss: 0.456, KL loss: 29.020. 
3250000/10108000 (epoch 33) loss: 4.801, gen loss: 1.323, ret loss: 0.137, fp loss: 0.449, KL loss: 28.910. 
3260000/10108000 (epoch 33) loss: 4.801, gen loss: 1.328, ret loss: 0.137, fp loss: 0.446, KL loss: 28.899. 
3270000/10108000 (epoch 33) loss: 4.799, gen loss: 1.329, ret loss: 0.136, fp loss: 0.444, KL loss: 28.890. 
3280000/10108000 (epoch 33) loss: 4.797, gen loss: 1.329, ret loss: 0.136, fp loss: 0.443, KL loss: 28.885. 
3290000/10108000 (epoch 33) loss: 4.794, gen loss: 1.329, ret loss: 0.136, fp loss: 0.442, KL loss: 28.876. 
3300000/10108000 (epoch 33) loss: 4.792, gen loss: 1.327, ret loss: 0.137, fp loss: 0.441, KL loss: 28.872. 
3310000/10108000 (epoch 33) loss: 4.786, gen loss: 1.323, ret loss: 0.137, fp loss: 0.441, KL loss: 28.853. 
3320000/10108000 (epoch 33) loss: 4.783, gen loss: 1.320, ret loss: 0.137, fp loss: 0.441, KL loss: 28.851. 
3330000/10108000 (epoch 33) loss: 4.780, gen loss: 1.317, ret loss: 0.137, fp loss: 0.442, KL loss: 28.848. 
Model checkpoint: save/all_data_10k_vocab/model33.ckpt. Average for epoch , loss: 4.779
3340000/10108000 (epoch 34) loss: 4.759, gen loss: 1.282, ret loss: 0.137, fp loss: 0.454, KL loss: 28.851. 
3350000/10108000 (epoch 34) loss: 4.774, gen loss: 1.298, ret loss: 0.136, fp loss: 0.453, KL loss: 28.855. 
3360000/10108000 (epoch 34) loss: 4.770, gen loss: 1.293, ret loss: 0.137, fp loss: 0.453, KL loss: 28.860. 
3370000/10108000 (epoch 34) loss: 4.759, gen loss: 1.291, ret loss: 0.137, fp loss: 0.449, KL loss: 28.821. 
3380000/10108000 (epoch 34) loss: 4.762, gen loss: 1.293, ret loss: 0.137, fp loss: 0.448, KL loss: 28.831. 
3390000/10108000 (epoch 34) loss: 4.760, gen loss: 1.293, ret loss: 0.137, fp loss: 0.447, KL loss: 28.830. 
3400000/10108000 (epoch 34) loss: 4.760, gen loss: 1.294, ret loss: 0.137, fp loss: 0.446, KL loss: 28.830. 
3410000/10108000 (epoch 34) loss: 4.764, gen loss: 1.297, ret loss: 0.137, fp loss: 0.447, KL loss: 28.835. 
3420000/10108000 (epoch 34) loss: 4.764, gen loss: 1.298, ret loss: 0.137, fp loss: 0.446, KL loss: 28.834. 
3430000/10108000 (epoch 34) loss: 4.763, gen loss: 1.297, ret loss: 0.137, fp loss: 0.446, KL loss: 28.834. 
Model checkpoint: save/all_data_10k_vocab/model34.ckpt. Average for epoch , loss: 4.763
3440000/10108000 (epoch 35) loss: 4.752, gen loss: 1.286, ret loss: 0.143, fp loss: 0.441, KL loss: 28.812. 
3450000/10108000 (epoch 35) loss: 4.773, gen loss: 1.297, ret loss: 0.140, fp loss: 0.449, KL loss: 28.871. 
3460000/10108000 (epoch 35) loss: 4.767, gen loss: 1.296, ret loss: 0.138, fp loss: 0.448, KL loss: 28.856. 
3470000/10108000 (epoch 35) loss: 4.764, gen loss: 1.297, ret loss: 0.137, fp loss: 0.446, KL loss: 28.833. 
3480000/10108000 (epoch 35) loss: 4.766, gen loss: 1.299, ret loss: 0.137, fp loss: 0.446, KL loss: 28.840. 
3490000/10108000 (epoch 35) loss: 4.766, gen loss: 1.300, ret loss: 0.137, fp loss: 0.445, KL loss: 28.842. 
3500000/10108000 (epoch 35) loss: 4.766, gen loss: 1.301, ret loss: 0.137, fp loss: 0.444, KL loss: 28.841. 
3510000/10108000 (epoch 35) loss: 4.767, gen loss: 1.302, ret loss: 0.137, fp loss: 0.444, KL loss: 28.839. 
3520000/10108000 (epoch 35) loss: 4.770, gen loss: 1.305, ret loss: 0.137, fp loss: 0.444, KL loss: 28.841. 
3530000/10108000 (epoch 35) loss: 4.776, gen loss: 1.310, ret loss: 0.136, fp loss: 0.445, KL loss: 28.846. 
Model checkpoint: save/all_data_10k_vocab/model35.ckpt. Average for epoch , loss: 4.778
3540000/10108000 (epoch 36) loss: 4.772, gen loss: 1.319, ret loss: 0.134, fp loss: 0.441, KL loss: 28.788. 
3550000/10108000 (epoch 36) loss: 4.799, gen loss: 1.334, ret loss: 0.135, fp loss: 0.447, KL loss: 28.818. 
3560000/10108000 (epoch 36) loss: 4.793, gen loss: 1.329, ret loss: 0.135, fp loss: 0.446, KL loss: 28.828. 
3570000/10108000 (epoch 36) loss: 4.791, gen loss: 1.326, ret loss: 0.135, fp loss: 0.445, KL loss: 28.840. 
3580000/10108000 (epoch 36) loss: 4.789, gen loss: 1.324, ret loss: 0.136, fp loss: 0.444, KL loss: 28.850. 
3590000/10108000 (epoch 36) loss: 4.786, gen loss: 1.323, ret loss: 0.136, fp loss: 0.443, KL loss: 28.841. 
3600000/10108000 (epoch 36) loss: 4.787, gen loss: 1.325, ret loss: 0.136, fp loss: 0.441, KL loss: 28.842. 
3610000/10108000 (epoch 36) loss: 4.788, gen loss: 1.327, ret loss: 0.136, fp loss: 0.441, KL loss: 28.848. 
3620000/10108000 (epoch 36) loss: 4.786, gen loss: 1.324, ret loss: 0.136, fp loss: 0.441, KL loss: 28.846. 
3630000/10108000 (epoch 36) loss: 4.786, gen loss: 1.323, ret loss: 0.137, fp loss: 0.442, KL loss: 28.848. 
Model checkpoint: save/all_data_10k_vocab/model36.ckpt. Average for epoch , loss: 4.785
3640000/10108000 (epoch 37) loss: 4.748, gen loss: 1.287, ret loss: 0.138, fp loss: 0.439, KL loss: 28.841. 
3650000/10108000 (epoch 37) loss: 4.776, gen loss: 1.307, ret loss: 0.140, fp loss: 0.445, KL loss: 28.845. 
3660000/10108000 (epoch 37) loss: 4.776, gen loss: 1.303, ret loss: 0.139, fp loss: 0.448, KL loss: 28.862. 
3670000/10108000 (epoch 37) loss: 4.783, gen loss: 1.309, ret loss: 0.138, fp loss: 0.449, KL loss: 28.874. 
3680000/10108000 (epoch 37) loss: 4.781, gen loss: 1.307, ret loss: 0.138, fp loss: 0.449, KL loss: 28.867. 
3690000/10108000 (epoch 37) loss: 4.786, gen loss: 1.310, ret loss: 0.138, fp loss: 0.450, KL loss: 28.878. 
3700000/10108000 (epoch 37) loss: 4.789, gen loss: 1.313, ret loss: 0.138, fp loss: 0.450, KL loss: 28.880. 
3710000/10108000 (epoch 37) loss: 4.782, gen loss: 1.309, ret loss: 0.138, fp loss: 0.448, KL loss: 28.866. 
3720000/10108000 (epoch 37) loss: 4.780, gen loss: 1.309, ret loss: 0.138, fp loss: 0.448, KL loss: 28.860. 
3730000/10108000 (epoch 37) loss: 4.780, gen loss: 1.308, ret loss: 0.138, fp loss: 0.449, KL loss: 28.857. 
Model checkpoint: save/all_data_10k_vocab/model37.ckpt. Average for epoch , loss: 4.781
3740000/10108000 (epoch 38) loss: 4.640, gen loss: 1.218, ret loss: 0.124, fp loss: 0.432, KL loss: 28.663. 
3750000/10108000 (epoch 38) loss: 4.803, gen loss: 1.320, ret loss: 0.139, fp loss: 0.455, KL loss: 28.899. 
3760000/10108000 (epoch 38) loss: 4.786, gen loss: 1.308, ret loss: 0.138, fp loss: 0.452, KL loss: 28.876. 
3770000/10108000 (epoch 38) loss: 4.789, gen loss: 1.310, ret loss: 0.138, fp loss: 0.451, KL loss: 28.897. 
3780000/10108000 (epoch 38) loss: 4.790, gen loss: 1.313, ret loss: 0.138, fp loss: 0.450, KL loss: 28.893. 
3790000/10108000 (epoch 38) loss: 4.792, gen loss: 1.316, ret loss: 0.138, fp loss: 0.449, KL loss: 28.888. 
3800000/10108000 (epoch 38) loss: 4.793, gen loss: 1.317, ret loss: 0.138, fp loss: 0.449, KL loss: 28.889. 
3810000/10108000 (epoch 38) loss: 4.797, gen loss: 1.322, ret loss: 0.138, fp loss: 0.449, KL loss: 28.882. 
3820000/10108000 (epoch 38) loss: 4.802, gen loss: 1.325, ret loss: 0.138, fp loss: 0.451, KL loss: 28.888. 
3830000/10108000 (epoch 38) loss: 4.805, gen loss: 1.328, ret loss: 0.137, fp loss: 0.451, KL loss: 28.888. 
3840000/10108000 (epoch 38) loss: 4.804, gen loss: 1.327, ret loss: 0.137, fp loss: 0.451, KL loss: 28.886. 
Model checkpoint: save/all_data_10k_vocab/model38.ckpt. Average for epoch , loss: 4.804
3850000/10108000 (epoch 39) loss: 4.817, gen loss: 1.333, ret loss: 0.136, fp loss: 0.462, KL loss: 28.861. 
3860000/10108000 (epoch 39) loss: 4.808, gen loss: 1.326, ret loss: 0.137, fp loss: 0.460, KL loss: 28.855. 
3870000/10108000 (epoch 39) loss: 4.803, gen loss: 1.322, ret loss: 0.137, fp loss: 0.458, KL loss: 28.858. 
3880000/10108000 (epoch 39) loss: 4.804, gen loss: 1.322, ret loss: 0.137, fp loss: 0.458, KL loss: 28.866. 
3890000/10108000 (epoch 39) loss: 4.803, gen loss: 1.321, ret loss: 0.137, fp loss: 0.458, KL loss: 28.866. 
3900000/10108000 (epoch 39) loss: 4.800, gen loss: 1.320, ret loss: 0.137, fp loss: 0.457, KL loss: 28.865. 
3910000/10108000 (epoch 39) loss: 4.800, gen loss: 1.321, ret loss: 0.137, fp loss: 0.456, KL loss: 28.860. 
3920000/10108000 (epoch 39) loss: 4.801, gen loss: 1.324, ret loss: 0.136, fp loss: 0.455, KL loss: 28.860. 
3930000/10108000 (epoch 39) loss: 4.800, gen loss: 1.325, ret loss: 0.136, fp loss: 0.454, KL loss: 28.855. 
3940000/10108000 (epoch 39) loss: 4.800, gen loss: 1.325, ret loss: 0.136, fp loss: 0.454, KL loss: 28.857. 
Model checkpoint: save/all_data_10k_vocab/model39.ckpt. Average for epoch , loss: 4.800
3950000/10108000 (epoch 40) loss: 4.797, gen loss: 1.333, ret loss: 0.132, fp loss: 0.449, KL loss: 28.833. 
3960000/10108000 (epoch 40) loss: 4.799, gen loss: 1.325, ret loss: 0.135, fp loss: 0.454, KL loss: 28.850. 
3970000/10108000 (epoch 40) loss: 4.794, gen loss: 1.324, ret loss: 0.135, fp loss: 0.451, KL loss: 28.845. 
3980000/10108000 (epoch 40) loss: 4.807, gen loss: 1.334, ret loss: 0.135, fp loss: 0.452, KL loss: 28.867. 
3990000/10108000 (epoch 40) loss: 4.811, gen loss: 1.336, ret loss: 0.135, fp loss: 0.453, KL loss: 28.875. 
4000000/10108000 (epoch 40) loss: 4.811, gen loss: 1.335, ret loss: 0.135, fp loss: 0.453, KL loss: 28.874. 
4010000/10108000 (epoch 40) loss: 4.808, gen loss: 1.333, ret loss: 0.135, fp loss: 0.453, KL loss: 28.869. 
4020000/10108000 (epoch 40) loss: 4.810, gen loss: 1.335, ret loss: 0.135, fp loss: 0.453, KL loss: 28.872. 
4030000/10108000 (epoch 40) loss: 4.810, gen loss: 1.335, ret loss: 0.135, fp loss: 0.453, KL loss: 28.865. 
4040000/10108000 (epoch 40) loss: 4.811, gen loss: 1.336, ret loss: 0.135, fp loss: 0.453, KL loss: 28.866. 
Model checkpoint: save/all_data_10k_vocab/model40.ckpt. Average for epoch , loss: 4.813
4050000/10108000 (epoch 41) loss: 4.800, gen loss: 1.338, ret loss: 0.137, fp loss: 0.447, KL loss: 28.788. 
4060000/10108000 (epoch 41) loss: 4.813, gen loss: 1.343, ret loss: 0.137, fp loss: 0.450, KL loss: 28.826. 
4070000/10108000 (epoch 41) loss: 4.818, gen loss: 1.342, ret loss: 0.137, fp loss: 0.454, KL loss: 28.857. 
4080000/10108000 (epoch 41) loss: 4.816, gen loss: 1.338, ret loss: 0.137, fp loss: 0.455, KL loss: 28.862. 
4090000/10108000 (epoch 41) loss: 4.815, gen loss: 1.336, ret loss: 0.137, fp loss: 0.455, KL loss: 28.871. 
4100000/10108000 (epoch 41) loss: 4.809, gen loss: 1.331, ret loss: 0.138, fp loss: 0.453, KL loss: 28.864. 
4110000/10108000 (epoch 41) loss: 4.805, gen loss: 1.327, ret loss: 0.138, fp loss: 0.453, KL loss: 28.863. 
4120000/10108000 (epoch 41) loss: 4.806, gen loss: 1.325, ret loss: 0.139, fp loss: 0.455, KL loss: 28.869. 
4130000/10108000 (epoch 41) loss: 4.804, gen loss: 1.324, ret loss: 0.139, fp loss: 0.454, KL loss: 28.868. 
4140000/10108000 (epoch 41) loss: 4.802, gen loss: 1.322, ret loss: 0.139, fp loss: 0.455, KL loss: 28.863. 
Model checkpoint: save/all_data_10k_vocab/model41.ckpt. Average for epoch , loss: 4.802
4150000/10108000 (epoch 42) loss: 4.786, gen loss: 1.312, ret loss: 0.141, fp loss: 0.449, KL loss: 28.848. 
4160000/10108000 (epoch 42) loss: 4.791, gen loss: 1.316, ret loss: 0.138, fp loss: 0.451, KL loss: 28.854. 
4170000/10108000 (epoch 42) loss: 4.799, gen loss: 1.321, ret loss: 0.137, fp loss: 0.454, KL loss: 28.872. 
4180000/10108000 (epoch 42) loss: 4.804, gen loss: 1.323, ret loss: 0.137, fp loss: 0.456, KL loss: 28.884. 
4190000/10108000 (epoch 42) loss: 4.811, gen loss: 1.326, ret loss: 0.138, fp loss: 0.458, KL loss: 28.893. 
4200000/10108000 (epoch 42) loss: 4.812, gen loss: 1.329, ret loss: 0.138, fp loss: 0.457, KL loss: 28.881. 
4210000/10108000 (epoch 42) loss: 4.809, gen loss: 1.328, ret loss: 0.137, fp loss: 0.456, KL loss: 28.876. 
4220000/10108000 (epoch 42) loss: 4.810, gen loss: 1.330, ret loss: 0.137, fp loss: 0.456, KL loss: 28.873. 
4230000/10108000 (epoch 42) loss: 4.810, gen loss: 1.330, ret loss: 0.138, fp loss: 0.456, KL loss: 28.874. 
4240000/10108000 (epoch 42) loss: 4.808, gen loss: 1.329, ret loss: 0.137, fp loss: 0.455, KL loss: 28.869. 
Model checkpoint: save/all_data_10k_vocab/model42.ckpt. Average for epoch , loss: 4.809
4250000/10108000 (epoch 43) loss: 4.827, gen loss: 1.347, ret loss: 0.138, fp loss: 0.453, KL loss: 28.901. 
4260000/10108000 (epoch 43) loss: 4.825, gen loss: 1.338, ret loss: 0.139, fp loss: 0.459, KL loss: 28.894. 
4270000/10108000 (epoch 43) loss: 4.823, gen loss: 1.336, ret loss: 0.140, fp loss: 0.458, KL loss: 28.901. 
4280000/10108000 (epoch 43) loss: 4.819, gen loss: 1.332, ret loss: 0.139, fp loss: 0.457, KL loss: 28.895. 
4290000/10108000 (epoch 43) loss: 4.820, gen loss: 1.333, ret loss: 0.139, fp loss: 0.458, KL loss: 28.893. 
4300000/10108000 (epoch 43) loss: 4.825, gen loss: 1.340, ret loss: 0.139, fp loss: 0.457, KL loss: 28.889. 
4310000/10108000 (epoch 43) loss: 4.824, gen loss: 1.339, ret loss: 0.139, fp loss: 0.458, KL loss: 28.889. 
4320000/10108000 (epoch 43) loss: 4.822, gen loss: 1.337, ret loss: 0.139, fp loss: 0.458, KL loss: 28.889. 
4330000/10108000 (epoch 43) loss: 4.821, gen loss: 1.337, ret loss: 0.139, fp loss: 0.457, KL loss: 28.886. 
4340000/10108000 (epoch 43) loss: 4.819, gen loss: 1.335, ret loss: 0.139, fp loss: 0.456, KL loss: 28.877. 
Model checkpoint: save/all_data_10k_vocab/model43.ckpt. Average for epoch , loss: 4.818
4350000/10108000 (epoch 44) loss: 4.799, gen loss: 1.339, ret loss: 0.139, fp loss: 0.440, KL loss: 28.796. 
4360000/10108000 (epoch 44) loss: 4.814, gen loss: 1.345, ret loss: 0.137, fp loss: 0.446, KL loss: 28.859. 
4370000/10108000 (epoch 44) loss: 4.794, gen loss: 1.326, ret loss: 0.138, fp loss: 0.445, KL loss: 28.850. 
4380000/10108000 (epoch 44) loss: 4.789, gen loss: 1.319, ret loss: 0.139, fp loss: 0.446, KL loss: 28.847. 
4390000/10108000 (epoch 44) loss: 4.787, gen loss: 1.317, ret loss: 0.139, fp loss: 0.447, KL loss: 28.836. 
4400000/10108000 (epoch 44) loss: 4.790, gen loss: 1.316, ret loss: 0.139, fp loss: 0.449, KL loss: 28.850. 
4410000/10108000 (epoch 44) loss: 4.789, gen loss: 1.315, ret loss: 0.140, fp loss: 0.449, KL loss: 28.857. 
4420000/10108000 (epoch 44) loss: 4.790, gen loss: 1.314, ret loss: 0.140, fp loss: 0.450, KL loss: 28.861. 
4430000/10108000 (epoch 44) loss: 4.790, gen loss: 1.314, ret loss: 0.140, fp loss: 0.450, KL loss: 28.866. 
4440000/10108000 (epoch 44) loss: 4.793, gen loss: 1.314, ret loss: 0.140, fp loss: 0.451, KL loss: 28.873. 
Model checkpoint: save/all_data_10k_vocab/model44.ckpt. Average for epoch , loss: 4.795
4450000/10108000 (epoch 45) loss: 4.830, gen loss: 1.349, ret loss: 0.137, fp loss: 0.454, KL loss: 28.899. 
4460000/10108000 (epoch 45) loss: 4.842, gen loss: 1.344, ret loss: 0.141, fp loss: 0.460, KL loss: 28.973. 
4470000/10108000 (epoch 45) loss: 4.828, gen loss: 1.334, ret loss: 0.141, fp loss: 0.459, KL loss: 28.934. 
4480000/10108000 (epoch 45) loss: 4.816, gen loss: 1.329, ret loss: 0.141, fp loss: 0.455, KL loss: 28.906. 
4490000/10108000 (epoch 45) loss: 4.809, gen loss: 1.330, ret loss: 0.141, fp loss: 0.451, KL loss: 28.881. 
4500000/10108000 (epoch 45) loss: 4.805, gen loss: 1.327, ret loss: 0.140, fp loss: 0.450, KL loss: 28.877. 
4510000/10108000 (epoch 45) loss: 4.802, gen loss: 1.325, ret loss: 0.140, fp loss: 0.449, KL loss: 28.880. 
4520000/10108000 (epoch 45) loss: 4.799, gen loss: 1.323, ret loss: 0.140, fp loss: 0.449, KL loss: 28.868. 
4530000/10108000 (epoch 45) loss: 4.799, gen loss: 1.324, ret loss: 0.140, fp loss: 0.450, KL loss: 28.865. 
4540000/10108000 (epoch 45) loss: 4.802, gen loss: 1.325, ret loss: 0.140, fp loss: 0.451, KL loss: 28.867. 
Model checkpoint: save/all_data_10k_vocab/model45.ckpt. Average for epoch , loss: 4.804
4550000/10108000 (epoch 46) loss: 4.768, gen loss: 1.317, ret loss: 0.144, fp loss: 0.432, KL loss: 28.744. 
4560000/10108000 (epoch 46) loss: 4.824, gen loss: 1.337, ret loss: 0.141, fp loss: 0.453, KL loss: 28.922. 
4570000/10108000 (epoch 46) loss: 4.816, gen loss: 1.327, ret loss: 0.141, fp loss: 0.456, KL loss: 28.918. 
4580000/10108000 (epoch 46) loss: 4.811, gen loss: 1.325, ret loss: 0.141, fp loss: 0.454, KL loss: 28.895. 
4590000/10108000 (epoch 46) loss: 4.810, gen loss: 1.327, ret loss: 0.141, fp loss: 0.453, KL loss: 28.895. 
4600000/10108000 (epoch 46) loss: 4.806, gen loss: 1.325, ret loss: 0.141, fp loss: 0.452, KL loss: 28.883. 
4610000/10108000 (epoch 46) loss: 4.809, gen loss: 1.326, ret loss: 0.141, fp loss: 0.453, KL loss: 28.895. 
4620000/10108000 (epoch 46) loss: 4.809, gen loss: 1.325, ret loss: 0.140, fp loss: 0.454, KL loss: 28.897. 
4630000/10108000 (epoch 46) loss: 4.808, gen loss: 1.324, ret loss: 0.140, fp loss: 0.455, KL loss: 28.891. 
4640000/10108000 (epoch 46) loss: 4.809, gen loss: 1.325, ret loss: 0.141, fp loss: 0.455, KL loss: 28.891. 
Model checkpoint: save/all_data_10k_vocab/model46.ckpt. Average for epoch , loss: 4.811
4650000/10108000 (epoch 47) loss: 4.816, gen loss: 1.328, ret loss: 0.139, fp loss: 0.448, KL loss: 29.006. 
4660000/10108000 (epoch 47) loss: 4.810, gen loss: 1.325, ret loss: 0.141, fp loss: 0.452, KL loss: 28.915. 
4670000/10108000 (epoch 47) loss: 4.810, gen loss: 1.323, ret loss: 0.140, fp loss: 0.456, KL loss: 28.906. 
4680000/10108000 (epoch 47) loss: 4.810, gen loss: 1.323, ret loss: 0.140, fp loss: 0.455, KL loss: 28.919. 
4690000/10108000 (epoch 47) loss: 4.820, gen loss: 1.331, ret loss: 0.140, fp loss: 0.456, KL loss: 28.933. 
4700000/10108000 (epoch 47) loss: 4.820, gen loss: 1.333, ret loss: 0.140, fp loss: 0.454, KL loss: 28.928. 
4710000/10108000 (epoch 47) loss: 4.822, gen loss: 1.336, ret loss: 0.140, fp loss: 0.454, KL loss: 28.928. 
4720000/10108000 (epoch 47) loss: 4.820, gen loss: 1.335, ret loss: 0.139, fp loss: 0.454, KL loss: 28.919. 
4730000/10108000 (epoch 47) loss: 4.819, gen loss: 1.335, ret loss: 0.139, fp loss: 0.454, KL loss: 28.912. 
4740000/10108000 (epoch 47) loss: 4.820, gen loss: 1.336, ret loss: 0.139, fp loss: 0.453, KL loss: 28.915. 
4750000/10108000 (epoch 47) loss: 4.819, gen loss: 1.335, ret loss: 0.140, fp loss: 0.453, KL loss: 28.911. 
Model checkpoint: save/all_data_10k_vocab/model47.ckpt. Average for epoch , loss: 4.819
4760000/10108000 (epoch 48) loss: 4.809, gen loss: 1.328, ret loss: 0.139, fp loss: 0.453, KL loss: 28.882. 
4770000/10108000 (epoch 48) loss: 4.820, gen loss: 1.329, ret loss: 0.140, fp loss: 0.458, KL loss: 28.930. 
4780000/10108000 (epoch 48) loss: 4.817, gen loss: 1.329, ret loss: 0.140, fp loss: 0.457, KL loss: 28.912. 
4790000/10108000 (epoch 48) loss: 4.818, gen loss: 1.330, ret loss: 0.140, fp loss: 0.457, KL loss: 28.911. 
4800000/10108000 (epoch 48) loss: 4.822, gen loss: 1.334, ret loss: 0.140, fp loss: 0.456, KL loss: 28.918. 
4810000/10108000 (epoch 48) loss: 4.824, gen loss: 1.337, ret loss: 0.140, fp loss: 0.456, KL loss: 28.915. 
4820000/10108000 (epoch 48) loss: 4.828, gen loss: 1.341, ret loss: 0.139, fp loss: 0.456, KL loss: 28.918. 
4830000/10108000 (epoch 48) loss: 4.827, gen loss: 1.341, ret loss: 0.139, fp loss: 0.455, KL loss: 28.911. 
4840000/10108000 (epoch 48) loss: 4.828, gen loss: 1.342, ret loss: 0.139, fp loss: 0.455, KL loss: 28.908. 
4850000/10108000 (epoch 48) loss: 4.830, gen loss: 1.344, ret loss: 0.139, fp loss: 0.456, KL loss: 28.909. 
Model checkpoint: save/all_data_10k_vocab/model48.ckpt. Average for epoch , loss: 4.829
4860000/10108000 (epoch 49) loss: 4.841, gen loss: 1.348, ret loss: 0.141, fp loss: 0.464, KL loss: 28.879. 
4870000/10108000 (epoch 49) loss: 4.831, gen loss: 1.339, ret loss: 0.142, fp loss: 0.461, KL loss: 28.894. 
4880000/10108000 (epoch 49) loss: 4.832, gen loss: 1.342, ret loss: 0.140, fp loss: 0.460, KL loss: 28.897. 
4890000/10108000 (epoch 49) loss: 4.832, gen loss: 1.343, ret loss: 0.140, fp loss: 0.459, KL loss: 28.895. 
4900000/10108000 (epoch 49) loss: 4.840, gen loss: 1.349, ret loss: 0.140, fp loss: 0.460, KL loss: 28.914. 
4910000/10108000 (epoch 49) loss: 4.839, gen loss: 1.348, ret loss: 0.140, fp loss: 0.460, KL loss: 28.911. 
4920000/10108000 (epoch 49) loss: 4.838, gen loss: 1.348, ret loss: 0.140, fp loss: 0.460, KL loss: 28.914. 
4930000/10108000 (epoch 49) loss: 4.839, gen loss: 1.347, ret loss: 0.140, fp loss: 0.459, KL loss: 28.921. 
4940000/10108000 (epoch 49) loss: 4.838, gen loss: 1.347, ret loss: 0.140, fp loss: 0.458, KL loss: 28.916. 
4950000/10108000 (epoch 49) loss: 4.838, gen loss: 1.346, ret loss: 0.141, fp loss: 0.459, KL loss: 28.925. 
Model checkpoint: save/all_data_10k_vocab/model49.ckpt. Average for epoch , loss: 4.838
4960000/10108000 (epoch 50) loss: 4.819, gen loss: 1.330, ret loss: 0.142, fp loss: 0.457, KL loss: 28.903. 
4970000/10108000 (epoch 50) loss: 4.832, gen loss: 1.330, ret loss: 0.143, fp loss: 0.463, KL loss: 28.959. 
4980000/10108000 (epoch 50) loss: 4.831, gen loss: 1.332, ret loss: 0.142, fp loss: 0.462, KL loss: 28.947. 
4990000/10108000 (epoch 50) loss: 4.848, gen loss: 1.348, ret loss: 0.142, fp loss: 0.462, KL loss: 28.959. 
5000000/10108000 (epoch 50) loss: 4.847, gen loss: 1.347, ret loss: 0.142, fp loss: 0.463, KL loss: 28.956. 
5010000/10108000 (epoch 50) loss: 4.844, gen loss: 1.344, ret loss: 0.142, fp loss: 0.462, KL loss: 28.957. 
5020000/10108000 (epoch 50) loss: 4.842, gen loss: 1.343, ret loss: 0.142, fp loss: 0.461, KL loss: 28.958. 
5030000/10108000 (epoch 50) loss: 4.846, gen loss: 1.346, ret loss: 0.142, fp loss: 0.461, KL loss: 28.968. 
5040000/10108000 (epoch 50) loss: 4.846, gen loss: 1.348, ret loss: 0.141, fp loss: 0.461, KL loss: 28.960. 
5050000/10108000 (epoch 50) loss: 4.851, gen loss: 1.351, ret loss: 0.141, fp loss: 0.462, KL loss: 28.966. 
Model checkpoint: save/all_data_10k_vocab/model50.ckpt. Average for epoch , loss: 4.852
5060000/10108000 (epoch 51) loss: 4.855, gen loss: 1.364, ret loss: 0.145, fp loss: 0.455, KL loss: 28.917. 
5070000/10108000 (epoch 51) loss: 4.840, gen loss: 1.349, ret loss: 0.143, fp loss: 0.458, KL loss: 28.899. 
5080000/10108000 (epoch 51) loss: 4.845, gen loss: 1.352, ret loss: 0.143, fp loss: 0.458, KL loss: 28.921. 
5090000/10108000 (epoch 51) loss: 4.847, gen loss: 1.354, ret loss: 0.142, fp loss: 0.458, KL loss: 28.926. 
5100000/10108000 (epoch 51) loss: 4.847, gen loss: 1.354, ret loss: 0.142, fp loss: 0.458, KL loss: 28.925. 
5110000/10108000 (epoch 51) loss: 4.851, gen loss: 1.356, ret loss: 0.142, fp loss: 0.460, KL loss: 28.939. 
5120000/10108000 (epoch 51) loss: 4.849, gen loss: 1.355, ret loss: 0.141, fp loss: 0.459, KL loss: 28.936. 
5130000/10108000 (epoch 51) loss: 4.847, gen loss: 1.354, ret loss: 0.141, fp loss: 0.459, KL loss: 28.930. 
5140000/10108000 (epoch 51) loss: 4.846, gen loss: 1.353, ret loss: 0.141, fp loss: 0.459, KL loss: 28.927. 
5150000/10108000 (epoch 51) loss: 4.843, gen loss: 1.350, ret loss: 0.141, fp loss: 0.459, KL loss: 28.924. 
Model checkpoint: save/all_data_10k_vocab/model51.ckpt. Average for epoch , loss: 4.844
5160000/10108000 (epoch 52) loss: 4.867, gen loss: 1.374, ret loss: 0.137, fp loss: 0.456, KL loss: 28.993. 
5170000/10108000 (epoch 52) loss: 4.863, gen loss: 1.366, ret loss: 0.142, fp loss: 0.461, KL loss: 28.949. 
5180000/10108000 (epoch 52) loss: 4.860, gen loss: 1.357, ret loss: 0.143, fp loss: 0.463, KL loss: 28.962. 
5190000/10108000 (epoch 52) loss: 4.863, gen loss: 1.356, ret loss: 0.144, fp loss: 0.465, KL loss: 28.974. 
5200000/10108000 (epoch 52) loss: 4.863, gen loss: 1.360, ret loss: 0.144, fp loss: 0.464, KL loss: 28.959. 
5210000/10108000 (epoch 52) loss: 4.862, gen loss: 1.359, ret loss: 0.144, fp loss: 0.463, KL loss: 28.954. 
5220000/10108000 (epoch 52) loss: 4.858, gen loss: 1.357, ret loss: 0.144, fp loss: 0.463, KL loss: 28.937. 
5230000/10108000 (epoch 52) loss: 4.857, gen loss: 1.357, ret loss: 0.144, fp loss: 0.463, KL loss: 28.933. 
5240000/10108000 (epoch 52) loss: 4.857, gen loss: 1.356, ret loss: 0.145, fp loss: 0.463, KL loss: 28.938. 
5250000/10108000 (epoch 52) loss: 4.854, gen loss: 1.354, ret loss: 0.145, fp loss: 0.463, KL loss: 28.930. 
Model checkpoint: save/all_data_10k_vocab/model52.ckpt. Average for epoch , loss: 4.854
5260000/10108000 (epoch 53) loss: 4.887, gen loss: 1.381, ret loss: 0.145, fp loss: 0.462, KL loss: 28.992. 
5270000/10108000 (epoch 53) loss: 4.889, gen loss: 1.383, ret loss: 0.142, fp loss: 0.464, KL loss: 28.993. 
5280000/10108000 (epoch 53) loss: 4.864, gen loss: 1.363, ret loss: 0.142, fp loss: 0.463, KL loss: 28.956. 
5290000/10108000 (epoch 53) loss: 4.861, gen loss: 1.358, ret loss: 0.143, fp loss: 0.464, KL loss: 28.959. 
5300000/10108000 (epoch 53) loss: 4.861, gen loss: 1.356, ret loss: 0.144, fp loss: 0.465, KL loss: 28.961. 
5310000/10108000 (epoch 53) loss: 4.859, gen loss: 1.356, ret loss: 0.144, fp loss: 0.464, KL loss: 28.951. 
5320000/10108000 (epoch 53) loss: 4.856, gen loss: 1.353, ret loss: 0.144, fp loss: 0.464, KL loss: 28.948. 
5330000/10108000 (epoch 53) loss: 4.855, gen loss: 1.352, ret loss: 0.144, fp loss: 0.464, KL loss: 28.947. 
5340000/10108000 (epoch 53) loss: 4.854, gen loss: 1.351, ret loss: 0.144, fp loss: 0.464, KL loss: 28.952. 
5350000/10108000 (epoch 53) loss: 4.852, gen loss: 1.349, ret loss: 0.144, fp loss: 0.463, KL loss: 28.947. 
Model checkpoint: save/all_data_10k_vocab/model53.ckpt. Average for epoch , loss: 4.853
5360000/10108000 (epoch 54) loss: 4.828, gen loss: 1.345, ret loss: 0.143, fp loss: 0.457, KL loss: 28.827. 
5370000/10108000 (epoch 54) loss: 4.895, gen loss: 1.384, ret loss: 0.145, fp loss: 0.469, KL loss: 28.975. 
5380000/10108000 (epoch 54) loss: 4.883, gen loss: 1.379, ret loss: 0.143, fp loss: 0.465, KL loss: 28.954. 
5390000/10108000 (epoch 54) loss: 4.871, gen loss: 1.373, ret loss: 0.143, fp loss: 0.462, KL loss: 28.930. 
5400000/10108000 (epoch 54) loss: 4.877, gen loss: 1.379, ret loss: 0.143, fp loss: 0.462, KL loss: 28.940. 
5410000/10108000 (epoch 54) loss: 4.878, gen loss: 1.380, ret loss: 0.142, fp loss: 0.463, KL loss: 28.929. 
5420000/10108000 (epoch 54) loss: 4.875, gen loss: 1.378, ret loss: 0.143, fp loss: 0.462, KL loss: 28.925. 
5430000/10108000 (epoch 54) loss: 4.875, gen loss: 1.377, ret loss: 0.143, fp loss: 0.463, KL loss: 28.925. 
5440000/10108000 (epoch 54) loss: 4.881, gen loss: 1.380, ret loss: 0.143, fp loss: 0.464, KL loss: 28.936. 
5450000/10108000 (epoch 54) loss: 4.880, gen loss: 1.380, ret loss: 0.143, fp loss: 0.464, KL loss: 28.932. 
Model checkpoint: save/all_data_10k_vocab/model54.ckpt. Average for epoch , loss: 4.883
5460000/10108000 (epoch 55) loss: 4.867, gen loss: 1.369, ret loss: 0.141, fp loss: 0.473, KL loss: 28.845. 
5470000/10108000 (epoch 55) loss: 4.881, gen loss: 1.381, ret loss: 0.144, fp loss: 0.465, KL loss: 28.905. 
5480000/10108000 (epoch 55) loss: 4.889, gen loss: 1.377, ret loss: 0.145, fp loss: 0.470, KL loss: 28.967. 
5490000/10108000 (epoch 55) loss: 4.886, gen loss: 1.376, ret loss: 0.145, fp loss: 0.470, KL loss: 28.957. 
5500000/10108000 (epoch 55) loss: 4.887, gen loss: 1.376, ret loss: 0.144, fp loss: 0.470, KL loss: 28.970. 
5510000/10108000 (epoch 55) loss: 4.886, gen loss: 1.375, ret loss: 0.145, fp loss: 0.469, KL loss: 28.965. 
5520000/10108000 (epoch 55) loss: 4.886, gen loss: 1.376, ret loss: 0.145, fp loss: 0.469, KL loss: 28.969. 
5530000/10108000 (epoch 55) loss: 4.884, gen loss: 1.374, ret loss: 0.145, fp loss: 0.469, KL loss: 28.965. 
5540000/10108000 (epoch 55) loss: 4.883, gen loss: 1.374, ret loss: 0.144, fp loss: 0.468, KL loss: 28.962. 
5550000/10108000 (epoch 55) loss: 4.883, gen loss: 1.374, ret loss: 0.144, fp loss: 0.469, KL loss: 28.958. 
Model checkpoint: save/all_data_10k_vocab/model55.ckpt. Average for epoch , loss: 4.882
5560000/10108000 (epoch 56) loss: 4.816, gen loss: 1.351, ret loss: 0.144, fp loss: 0.454, KL loss: 28.675. 
5570000/10108000 (epoch 56) loss: 4.887, gen loss: 1.379, ret loss: 0.147, fp loss: 0.468, KL loss: 28.931. 
5580000/10108000 (epoch 56) loss: 4.880, gen loss: 1.369, ret loss: 0.146, fp loss: 0.470, KL loss: 28.948. 
5590000/10108000 (epoch 56) loss: 4.883, gen loss: 1.374, ret loss: 0.145, fp loss: 0.469, KL loss: 28.957. 
5600000/10108000 (epoch 56) loss: 4.883, gen loss: 1.374, ret loss: 0.145, fp loss: 0.468, KL loss: 28.963. 
5610000/10108000 (epoch 56) loss: 4.881, gen loss: 1.372, ret loss: 0.145, fp loss: 0.467, KL loss: 28.956. 
5620000/10108000 (epoch 56) loss: 4.881, gen loss: 1.374, ret loss: 0.146, fp loss: 0.465, KL loss: 28.963. 
5630000/10108000 (epoch 56) loss: 4.879, gen loss: 1.372, ret loss: 0.145, fp loss: 0.465, KL loss: 28.961. 
5640000/10108000 (epoch 56) loss: 4.882, gen loss: 1.376, ret loss: 0.145, fp loss: 0.465, KL loss: 28.963. 
5650000/10108000 (epoch 56) loss: 4.883, gen loss: 1.376, ret loss: 0.145, fp loss: 0.465, KL loss: 28.963. 
5660000/10108000 (epoch 56) loss: 4.884, gen loss: 1.377, ret loss: 0.145, fp loss: 0.465, KL loss: 28.960. 
Model checkpoint: save/all_data_10k_vocab/model56.ckpt. Average for epoch , loss: 4.884
5670000/10108000 (epoch 57) loss: 4.878, gen loss: 1.383, ret loss: 0.147, fp loss: 0.462, KL loss: 28.859. 
5680000/10108000 (epoch 57) loss: 4.872, gen loss: 1.373, ret loss: 0.147, fp loss: 0.461, KL loss: 28.899. 
5690000/10108000 (epoch 57) loss: 4.868, gen loss: 1.373, ret loss: 0.147, fp loss: 0.459, KL loss: 28.892. 
5700000/10108000 (epoch 57) loss: 4.874, gen loss: 1.378, ret loss: 0.145, fp loss: 0.459, KL loss: 28.911. 
5710000/10108000 (epoch 57) loss: 4.876, gen loss: 1.380, ret loss: 0.145, fp loss: 0.459, KL loss: 28.918. 
5720000/10108000 (epoch 57) loss: 4.875, gen loss: 1.380, ret loss: 0.145, fp loss: 0.459, KL loss: 28.922. 
5730000/10108000 (epoch 57) loss: 4.871, gen loss: 1.377, ret loss: 0.144, fp loss: 0.457, KL loss: 28.921. 
5740000/10108000 (epoch 57) loss: 4.866, gen loss: 1.373, ret loss: 0.145, fp loss: 0.457, KL loss: 28.914. 
5750000/10108000 (epoch 57) loss: 4.864, gen loss: 1.371, ret loss: 0.145, fp loss: 0.456, KL loss: 28.913. 
5760000/10108000 (epoch 57) loss: 4.864, gen loss: 1.372, ret loss: 0.145, fp loss: 0.456, KL loss: 28.914. 
Model checkpoint: save/all_data_10k_vocab/model57.ckpt. Average for epoch , loss: 4.864
5770000/10108000 (epoch 58) loss: 4.867, gen loss: 1.382, ret loss: 0.144, fp loss: 0.446, KL loss: 28.955. 
5780000/10108000 (epoch 58) loss: 4.857, gen loss: 1.368, ret loss: 0.145, fp loss: 0.450, KL loss: 28.936. 
5790000/10108000 (epoch 58) loss: 4.845, gen loss: 1.361, ret loss: 0.145, fp loss: 0.449, KL loss: 28.911. 
5800000/10108000 (epoch 58) loss: 4.851, gen loss: 1.366, ret loss: 0.145, fp loss: 0.448, KL loss: 28.925. 
5810000/10108000 (epoch 58) loss: 4.854, gen loss: 1.365, ret loss: 0.145, fp loss: 0.449, KL loss: 28.941. 
5820000/10108000 (epoch 58) loss: 4.849, gen loss: 1.360, ret loss: 0.146, fp loss: 0.450, KL loss: 28.930. 
5830000/10108000 (epoch 58) loss: 4.846, gen loss: 1.359, ret loss: 0.145, fp loss: 0.449, KL loss: 28.920. 
5840000/10108000 (epoch 58) loss: 4.850, gen loss: 1.361, ret loss: 0.146, fp loss: 0.450, KL loss: 28.931. 
5850000/10108000 (epoch 58) loss: 4.850, gen loss: 1.361, ret loss: 0.146, fp loss: 0.451, KL loss: 28.927. 
5860000/10108000 (epoch 58) loss: 4.854, gen loss: 1.363, ret loss: 0.146, fp loss: 0.452, KL loss: 28.936. 
Model checkpoint: save/all_data_10k_vocab/model58.ckpt. Average for epoch , loss: 4.854
5870000/10108000 (epoch 59) loss: 4.884, gen loss: 1.390, ret loss: 0.141, fp loss: 0.456, KL loss: 28.981. 
5880000/10108000 (epoch 59) loss: 4.883, gen loss: 1.382, ret loss: 0.145, fp loss: 0.459, KL loss: 28.974. 
5890000/10108000 (epoch 59) loss: 4.872, gen loss: 1.376, ret loss: 0.145, fp loss: 0.457, KL loss: 28.944. 
5900000/10108000 (epoch 59) loss: 4.862, gen loss: 1.369, ret loss: 0.145, fp loss: 0.455, KL loss: 28.932. 
5910000/10108000 (epoch 59) loss: 4.866, gen loss: 1.369, ret loss: 0.146, fp loss: 0.455, KL loss: 28.953. 
5920000/10108000 (epoch 59) loss: 4.867, gen loss: 1.370, ret loss: 0.147, fp loss: 0.455, KL loss: 28.951. 
5930000/10108000 (epoch 59) loss: 4.866, gen loss: 1.371, ret loss: 0.146, fp loss: 0.455, KL loss: 28.946. 
5940000/10108000 (epoch 59) loss: 4.869, gen loss: 1.373, ret loss: 0.146, fp loss: 0.454, KL loss: 28.948. 
5950000/10108000 (epoch 59) loss: 4.866, gen loss: 1.373, ret loss: 0.146, fp loss: 0.453, KL loss: 28.942. 
5960000/10108000 (epoch 59) loss: 4.868, gen loss: 1.374, ret loss: 0.146, fp loss: 0.453, KL loss: 28.945. 
Model checkpoint: save/all_data_10k_vocab/model59.ckpt. Average for epoch , loss: 4.867
5970000/10108000 (epoch 60) loss: 4.880, gen loss: 1.382, ret loss: 0.150, fp loss: 0.453, KL loss: 28.949. 
5980000/10108000 (epoch 60) loss: 4.875, gen loss: 1.377, ret loss: 0.148, fp loss: 0.457, KL loss: 28.934. 
5990000/10108000 (epoch 60) loss: 4.855, gen loss: 1.360, ret loss: 0.148, fp loss: 0.456, KL loss: 28.913. 
6000000/10108000 (epoch 60) loss: 4.851, gen loss: 1.357, ret loss: 0.147, fp loss: 0.456, KL loss: 28.910. 
6010000/10108000 (epoch 60) loss: 4.860, gen loss: 1.362, ret loss: 0.148, fp loss: 0.458, KL loss: 28.928. 
6020000/10108000 (epoch 60) loss: 4.866, gen loss: 1.364, ret loss: 0.147, fp loss: 0.460, KL loss: 28.942. 
6030000/10108000 (epoch 60) loss: 4.870, gen loss: 1.369, ret loss: 0.147, fp loss: 0.460, KL loss: 28.941. 
6040000/10108000 (epoch 60) loss: 4.869, gen loss: 1.371, ret loss: 0.146, fp loss: 0.458, KL loss: 28.929. 
6050000/10108000 (epoch 60) loss: 4.869, gen loss: 1.373, ret loss: 0.146, fp loss: 0.458, KL loss: 28.923. 
6060000/10108000 (epoch 60) loss: 4.868, gen loss: 1.373, ret loss: 0.145, fp loss: 0.457, KL loss: 28.916. 
Model checkpoint: save/all_data_10k_vocab/model60.ckpt. Average for epoch , loss: 4.868
6070000/10108000 (epoch 61) loss: 4.917, gen loss: 1.414, ret loss: 0.143, fp loss: 0.455, KL loss: 29.055. 
6080000/10108000 (epoch 61) loss: 4.888, gen loss: 1.395, ret loss: 0.142, fp loss: 0.453, KL loss: 28.975. 
6090000/10108000 (epoch 61) loss: 4.876, gen loss: 1.383, ret loss: 0.143, fp loss: 0.454, KL loss: 28.965. 
6100000/10108000 (epoch 61) loss: 4.871, gen loss: 1.379, ret loss: 0.144, fp loss: 0.454, KL loss: 28.944. 
6110000/10108000 (epoch 61) loss: 4.880, gen loss: 1.382, ret loss: 0.145, fp loss: 0.456, KL loss: 28.972. 
6120000/10108000 (epoch 61) loss: 4.886, gen loss: 1.384, ret loss: 0.146, fp loss: 0.457, KL loss: 28.982. 
6130000/10108000 (epoch 61) loss: 4.886, gen loss: 1.383, ret loss: 0.146, fp loss: 0.459, KL loss: 28.984. 
6140000/10108000 (epoch 61) loss: 4.882, gen loss: 1.382, ret loss: 0.146, fp loss: 0.458, KL loss: 28.964. 
6150000/10108000 (epoch 61) loss: 4.884, gen loss: 1.383, ret loss: 0.146, fp loss: 0.459, KL loss: 28.967. 
6160000/10108000 (epoch 61) loss: 4.885, gen loss: 1.384, ret loss: 0.146, fp loss: 0.459, KL loss: 28.961. 
Model checkpoint: save/all_data_10k_vocab/model61.ckpt. Average for epoch , loss: 4.885
6170000/10108000 (epoch 62) loss: 4.892, gen loss: 1.384, ret loss: 0.149, fp loss: 0.463, KL loss: 28.966. 
6180000/10108000 (epoch 62) loss: 4.887, gen loss: 1.382, ret loss: 0.148, fp loss: 0.464, KL loss: 28.934. 
6190000/10108000 (epoch 62) loss: 4.891, gen loss: 1.386, ret loss: 0.148, fp loss: 0.463, KL loss: 28.947. 
6200000/10108000 (epoch 62) loss: 4.887, gen loss: 1.385, ret loss: 0.147, fp loss: 0.462, KL loss: 28.927. 
6210000/10108000 (epoch 62) loss: 4.886, gen loss: 1.386, ret loss: 0.147, fp loss: 0.461, KL loss: 28.925. 
6220000/10108000 (epoch 62) loss: 4.889, gen loss: 1.388, ret loss: 0.147, fp loss: 0.460, KL loss: 28.933. 
6230000/10108000 (epoch 62) loss: 4.890, gen loss: 1.391, ret loss: 0.147, fp loss: 0.459, KL loss: 28.934. 
6240000/10108000 (epoch 62) loss: 4.888, gen loss: 1.391, ret loss: 0.146, fp loss: 0.458, KL loss: 28.929. 
6250000/10108000 (epoch 62) loss: 4.889, gen loss: 1.393, ret loss: 0.146, fp loss: 0.458, KL loss: 28.919. 
6260000/10108000 (epoch 62) loss: 4.892, gen loss: 1.397, ret loss: 0.145, fp loss: 0.457, KL loss: 28.918. 
Model checkpoint: save/all_data_10k_vocab/model62.ckpt. Average for epoch , loss: 4.893
6270000/10108000 (epoch 63) loss: 4.935, gen loss: 1.443, ret loss: 0.138, fp loss: 0.463, KL loss: 28.915. 
6280000/10108000 (epoch 63) loss: 4.925, gen loss: 1.433, ret loss: 0.142, fp loss: 0.459, KL loss: 28.905. 
6290000/10108000 (epoch 63) loss: 4.911, gen loss: 1.421, ret loss: 0.143, fp loss: 0.458, KL loss: 28.887. 
6300000/10108000 (epoch 63) loss: 4.905, gen loss: 1.419, ret loss: 0.142, fp loss: 0.457, KL loss: 28.863. 
6310000/10108000 (epoch 63) loss: 4.901, gen loss: 1.417, ret loss: 0.142, fp loss: 0.455, KL loss: 28.868. 
6320000/10108000 (epoch 63) loss: 4.907, gen loss: 1.420, ret loss: 0.143, fp loss: 0.456, KL loss: 28.886. 
6330000/10108000 (epoch 63) loss: 4.905, gen loss: 1.418, ret loss: 0.143, fp loss: 0.455, KL loss: 28.889. 
6340000/10108000 (epoch 63) loss: 4.903, gen loss: 1.416, ret loss: 0.143, fp loss: 0.456, KL loss: 28.889. 
6350000/10108000 (epoch 63) loss: 4.904, gen loss: 1.416, ret loss: 0.143, fp loss: 0.456, KL loss: 28.885. 
6360000/10108000 (epoch 63) loss: 4.903, gen loss: 1.414, ret loss: 0.143, fp loss: 0.456, KL loss: 28.888. 
Model checkpoint: save/all_data_10k_vocab/model63.ckpt. Average for epoch , loss: 4.903
6370000/10108000 (epoch 64) loss: 4.852, gen loss: 1.379, ret loss: 0.142, fp loss: 0.451, KL loss: 28.806. 
6380000/10108000 (epoch 64) loss: 4.897, gen loss: 1.401, ret loss: 0.146, fp loss: 0.461, KL loss: 28.891. 
6390000/10108000 (epoch 64) loss: 4.885, gen loss: 1.394, ret loss: 0.147, fp loss: 0.455, KL loss: 28.886. 
6400000/10108000 (epoch 64) loss: 4.883, gen loss: 1.393, ret loss: 0.146, fp loss: 0.456, KL loss: 28.887. 
6410000/10108000 (epoch 64) loss: 4.891, gen loss: 1.399, ret loss: 0.146, fp loss: 0.455, KL loss: 28.908. 
6420000/10108000 (epoch 64) loss: 4.889, gen loss: 1.399, ret loss: 0.145, fp loss: 0.456, KL loss: 28.895. 
6430000/10108000 (epoch 64) loss: 4.889, gen loss: 1.399, ret loss: 0.145, fp loss: 0.456, KL loss: 28.897. 
6440000/10108000 (epoch 64) loss: 4.888, gen loss: 1.395, ret loss: 0.146, fp loss: 0.456, KL loss: 28.911. 
6450000/10108000 (epoch 64) loss: 4.888, gen loss: 1.394, ret loss: 0.146, fp loss: 0.456, KL loss: 28.913. 
6460000/10108000 (epoch 64) loss: 4.888, gen loss: 1.395, ret loss: 0.146, fp loss: 0.456, KL loss: 28.907. 
Model checkpoint: save/all_data_10k_vocab/model64.ckpt. Average for epoch , loss: 4.888
6470000/10108000 (epoch 65) loss: 4.789, gen loss: 1.346, ret loss: 0.144, fp loss: 0.434, KL loss: 28.650. 
6480000/10108000 (epoch 65) loss: 4.871, gen loss: 1.375, ret loss: 0.146, fp loss: 0.462, KL loss: 28.870. 
6490000/10108000 (epoch 65) loss: 4.867, gen loss: 1.369, ret loss: 0.146, fp loss: 0.461, KL loss: 28.901. 
6500000/10108000 (epoch 65) loss: 4.867, gen loss: 1.372, ret loss: 0.147, fp loss: 0.457, KL loss: 28.903. 
6510000/10108000 (epoch 65) loss: 4.866, gen loss: 1.373, ret loss: 0.147, fp loss: 0.455, KL loss: 28.900. 
6520000/10108000 (epoch 65) loss: 4.868, gen loss: 1.376, ret loss: 0.147, fp loss: 0.455, KL loss: 28.904. 
6530000/10108000 (epoch 65) loss: 4.877, gen loss: 1.381, ret loss: 0.147, fp loss: 0.456, KL loss: 28.930. 
6540000/10108000 (epoch 65) loss: 4.883, gen loss: 1.384, ret loss: 0.146, fp loss: 0.458, KL loss: 28.937. 
6550000/10108000 (epoch 65) loss: 4.885, gen loss: 1.385, ret loss: 0.146, fp loss: 0.459, KL loss: 28.943. 
6560000/10108000 (epoch 65) loss: 4.891, gen loss: 1.387, ret loss: 0.147, fp loss: 0.461, KL loss: 28.958. 
6570000/10108000 (epoch 65) loss: 4.894, gen loss: 1.389, ret loss: 0.147, fp loss: 0.462, KL loss: 28.958. 
Model checkpoint: save/all_data_10k_vocab/model65.ckpt. Average for epoch , loss: 4.893
6580000/10108000 (epoch 66) loss: 4.906, gen loss: 1.394, ret loss: 0.150, fp loss: 0.468, KL loss: 28.941. 
6590000/10108000 (epoch 66) loss: 4.901, gen loss: 1.389, ret loss: 0.150, fp loss: 0.467, KL loss: 28.943. 
6600000/10108000 (epoch 66) loss: 4.898, gen loss: 1.391, ret loss: 0.150, fp loss: 0.464, KL loss: 28.927. 
6610000/10108000 (epoch 66) loss: 4.916, gen loss: 1.403, ret loss: 0.150, fp loss: 0.465, KL loss: 28.982. 
6620000/10108000 (epoch 66) loss: 4.913, gen loss: 1.403, ret loss: 0.150, fp loss: 0.464, KL loss: 28.964. 
6630000/10108000 (epoch 66) loss: 4.912, gen loss: 1.403, ret loss: 0.149, fp loss: 0.464, KL loss: 28.964. 
6640000/10108000 (epoch 66) loss: 4.911, gen loss: 1.404, ret loss: 0.149, fp loss: 0.463, KL loss: 28.956. 
6650000/10108000 (epoch 66) loss: 4.909, gen loss: 1.404, ret loss: 0.149, fp loss: 0.462, KL loss: 28.943. 
6660000/10108000 (epoch 66) loss: 4.907, gen loss: 1.403, ret loss: 0.149, fp loss: 0.462, KL loss: 28.933. 
6670000/10108000 (epoch 66) loss: 4.913, gen loss: 1.405, ret loss: 0.149, fp loss: 0.464, KL loss: 28.943. 
Model checkpoint: save/all_data_10k_vocab/model66.ckpt. Average for epoch , loss: 4.912
6680000/10108000 (epoch 67) loss: 4.908, gen loss: 1.402, ret loss: 0.149, fp loss: 0.466, KL loss: 28.907. 
6690000/10108000 (epoch 67) loss: 4.906, gen loss: 1.402, ret loss: 0.149, fp loss: 0.463, KL loss: 28.919. 
6700000/10108000 (epoch 67) loss: 4.897, gen loss: 1.397, ret loss: 0.149, fp loss: 0.461, KL loss: 28.897. 
6710000/10108000 (epoch 67) loss: 4.899, gen loss: 1.397, ret loss: 0.149, fp loss: 0.462, KL loss: 28.907. 
6720000/10108000 (epoch 67) loss: 4.894, gen loss: 1.395, ret loss: 0.149, fp loss: 0.461, KL loss: 28.894. 
6730000/10108000 (epoch 67) loss: 4.894, gen loss: 1.396, ret loss: 0.149, fp loss: 0.459, KL loss: 28.901. 
6740000/10108000 (epoch 67) loss: 4.898, gen loss: 1.396, ret loss: 0.149, fp loss: 0.461, KL loss: 28.926. 
6750000/10108000 (epoch 67) loss: 4.900, gen loss: 1.397, ret loss: 0.149, fp loss: 0.462, KL loss: 28.921. 
6760000/10108000 (epoch 67) loss: 4.900, gen loss: 1.397, ret loss: 0.149, fp loss: 0.462, KL loss: 28.918. 
6770000/10108000 (epoch 67) loss: 4.900, gen loss: 1.397, ret loss: 0.149, fp loss: 0.462, KL loss: 28.915. 
Model checkpoint: save/all_data_10k_vocab/model67.ckpt. Average for epoch , loss: 4.900
6780000/10108000 (epoch 68) loss: 4.905, gen loss: 1.397, ret loss: 0.154, fp loss: 0.464, KL loss: 28.902. 
6790000/10108000 (epoch 68) loss: 4.901, gen loss: 1.394, ret loss: 0.153, fp loss: 0.464, KL loss: 28.907. 
6800000/10108000 (epoch 68) loss: 4.898, gen loss: 1.395, ret loss: 0.152, fp loss: 0.462, KL loss: 28.897. 
6810000/10108000 (epoch 68) loss: 4.895, gen loss: 1.396, ret loss: 0.151, fp loss: 0.460, KL loss: 28.882. 
6820000/10108000 (epoch 68) loss: 4.903, gen loss: 1.400, ret loss: 0.152, fp loss: 0.460, KL loss: 28.910. 
6830000/10108000 (epoch 68) loss: 4.906, gen loss: 1.403, ret loss: 0.152, fp loss: 0.460, KL loss: 28.917. 
6840000/10108000 (epoch 68) loss: 4.905, gen loss: 1.402, ret loss: 0.152, fp loss: 0.460, KL loss: 28.906. 
6850000/10108000 (epoch 68) loss: 4.903, gen loss: 1.401, ret loss: 0.152, fp loss: 0.460, KL loss: 28.900. 
6860000/10108000 (epoch 68) loss: 4.905, gen loss: 1.404, ret loss: 0.151, fp loss: 0.460, KL loss: 28.898. 
6870000/10108000 (epoch 68) loss: 4.904, gen loss: 1.404, ret loss: 0.151, fp loss: 0.460, KL loss: 28.893. 
Model checkpoint: save/all_data_10k_vocab/model68.ckpt. Average for epoch , loss: 4.904
6880000/10108000 (epoch 69) loss: 4.940, gen loss: 1.424, ret loss: 0.155, fp loss: 0.473, KL loss: 28.882. 
6890000/10108000 (epoch 69) loss: 4.910, gen loss: 1.402, ret loss: 0.152, fp loss: 0.466, KL loss: 28.899. 
6900000/10108000 (epoch 69) loss: 4.911, gen loss: 1.401, ret loss: 0.151, fp loss: 0.466, KL loss: 28.930. 
6910000/10108000 (epoch 69) loss: 4.912, gen loss: 1.404, ret loss: 0.150, fp loss: 0.465, KL loss: 28.932. 
6920000/10108000 (epoch 69) loss: 4.915, gen loss: 1.407, ret loss: 0.151, fp loss: 0.465, KL loss: 28.931. 
6930000/10108000 (epoch 69) loss: 4.913, gen loss: 1.406, ret loss: 0.151, fp loss: 0.463, KL loss: 28.924. 
6940000/10108000 (epoch 69) loss: 4.909, gen loss: 1.405, ret loss: 0.151, fp loss: 0.462, KL loss: 28.914. 
6950000/10108000 (epoch 69) loss: 4.908, gen loss: 1.403, ret loss: 0.151, fp loss: 0.462, KL loss: 28.910. 
6960000/10108000 (epoch 69) loss: 4.906, gen loss: 1.402, ret loss: 0.151, fp loss: 0.462, KL loss: 28.907. 
6970000/10108000 (epoch 69) loss: 4.908, gen loss: 1.403, ret loss: 0.152, fp loss: 0.462, KL loss: 28.917. 
Model checkpoint: save/all_data_10k_vocab/model69.ckpt. Average for epoch , loss: 4.910
6980000/10108000 (epoch 70) loss: 4.925, gen loss: 1.402, ret loss: 0.160, fp loss: 0.468, KL loss: 28.958. 
6990000/10108000 (epoch 70) loss: 4.922, gen loss: 1.402, ret loss: 0.158, fp loss: 0.468, KL loss: 28.942. 
7000000/10108000 (epoch 70) loss: 4.909, gen loss: 1.398, ret loss: 0.156, fp loss: 0.464, KL loss: 28.910. 
7010000/10108000 (epoch 70) loss: 4.910, gen loss: 1.400, ret loss: 0.154, fp loss: 0.464, KL loss: 28.909. 
7020000/10108000 (epoch 70) loss: 4.908, gen loss: 1.401, ret loss: 0.155, fp loss: 0.462, KL loss: 28.903. 
7030000/10108000 (epoch 70) loss: 4.911, gen loss: 1.402, ret loss: 0.155, fp loss: 0.462, KL loss: 28.918. 
7040000/10108000 (epoch 70) loss: 4.906, gen loss: 1.400, ret loss: 0.155, fp loss: 0.461, KL loss: 28.905. 
7050000/10108000 (epoch 70) loss: 4.902, gen loss: 1.398, ret loss: 0.154, fp loss: 0.460, KL loss: 28.899. 
7060000/10108000 (epoch 70) loss: 4.901, gen loss: 1.398, ret loss: 0.154, fp loss: 0.459, KL loss: 28.900. 
7070000/10108000 (epoch 70) loss: 4.900, gen loss: 1.396, ret loss: 0.154, fp loss: 0.459, KL loss: 28.903. 
Model checkpoint: save/all_data_10k_vocab/model70.ckpt. Average for epoch , loss: 4.899
7080000/10108000 (epoch 71) loss: 4.883, gen loss: 1.377, ret loss: 0.154, fp loss: 0.457, KL loss: 28.942. 
7090000/10108000 (epoch 71) loss: 4.871, gen loss: 1.376, ret loss: 0.152, fp loss: 0.455, KL loss: 28.884. 
7100000/10108000 (epoch 71) loss: 4.875, gen loss: 1.377, ret loss: 0.152, fp loss: 0.455, KL loss: 28.905. 
7110000/10108000 (epoch 71) loss: 4.884, gen loss: 1.387, ret loss: 0.152, fp loss: 0.453, KL loss: 28.920. 
7120000/10108000 (epoch 71) loss: 4.890, gen loss: 1.392, ret loss: 0.152, fp loss: 0.454, KL loss: 28.921. 
7130000/10108000 (epoch 71) loss: 4.893, gen loss: 1.395, ret loss: 0.152, fp loss: 0.455, KL loss: 28.918. 
7140000/10108000 (epoch 71) loss: 4.896, gen loss: 1.395, ret loss: 0.152, fp loss: 0.456, KL loss: 28.923. 
7150000/10108000 (epoch 71) loss: 4.893, gen loss: 1.394, ret loss: 0.152, fp loss: 0.457, KL loss: 28.915. 
7160000/10108000 (epoch 71) loss: 4.899, gen loss: 1.396, ret loss: 0.152, fp loss: 0.458, KL loss: 28.930. 
7170000/10108000 (epoch 71) loss: 4.904, gen loss: 1.398, ret loss: 0.153, fp loss: 0.459, KL loss: 28.945. 
Model checkpoint: save/all_data_10k_vocab/model71.ckpt. Average for epoch , loss: 4.906
7180000/10108000 (epoch 72) loss: 4.976, gen loss: 1.430, ret loss: 0.163, fp loss: 0.469, KL loss: 29.146. 
7190000/10108000 (epoch 72) loss: 4.961, gen loss: 1.432, ret loss: 0.158, fp loss: 0.468, KL loss: 29.019. 
7200000/10108000 (epoch 72) loss: 4.948, gen loss: 1.423, ret loss: 0.158, fp loss: 0.467, KL loss: 29.009. 
7210000/10108000 (epoch 72) loss: 4.951, gen loss: 1.423, ret loss: 0.159, fp loss: 0.468, KL loss: 29.021. 
7220000/10108000 (epoch 72) loss: 4.950, gen loss: 1.424, ret loss: 0.158, fp loss: 0.466, KL loss: 29.008. 
7230000/10108000 (epoch 72) loss: 4.948, gen loss: 1.423, ret loss: 0.158, fp loss: 0.466, KL loss: 29.010. 
7240000/10108000 (epoch 72) loss: 4.946, gen loss: 1.423, ret loss: 0.157, fp loss: 0.465, KL loss: 29.007. 
7250000/10108000 (epoch 72) loss: 4.942, gen loss: 1.420, ret loss: 0.157, fp loss: 0.464, KL loss: 29.007. 
7260000/10108000 (epoch 72) loss: 4.948, gen loss: 1.423, ret loss: 0.157, fp loss: 0.466, KL loss: 29.020. 
7270000/10108000 (epoch 72) loss: 4.944, gen loss: 1.421, ret loss: 0.157, fp loss: 0.466, KL loss: 29.004. 
Model checkpoint: save/all_data_10k_vocab/model72.ckpt. Average for epoch , loss: 4.944
7280000/10108000 (epoch 73) loss: 4.909, gen loss: 1.403, ret loss: 0.155, fp loss: 0.463, KL loss: 28.883. 
7290000/10108000 (epoch 73) loss: 4.935, gen loss: 1.409, ret loss: 0.157, fp loss: 0.470, KL loss: 28.993. 
7300000/10108000 (epoch 73) loss: 4.933, gen loss: 1.409, ret loss: 0.157, fp loss: 0.470, KL loss: 28.969. 
7310000/10108000 (epoch 73) loss: 4.932, gen loss: 1.407, ret loss: 0.158, fp loss: 0.471, KL loss: 28.954. 
7320000/10108000 (epoch 73) loss: 4.935, gen loss: 1.410, ret loss: 0.158, fp loss: 0.471, KL loss: 28.961. 
7330000/10108000 (epoch 73) loss: 4.931, gen loss: 1.409, ret loss: 0.157, fp loss: 0.469, KL loss: 28.954. 
7340000/10108000 (epoch 73) loss: 4.931, gen loss: 1.410, ret loss: 0.157, fp loss: 0.468, KL loss: 28.964. 
7350000/10108000 (epoch 73) loss: 4.927, gen loss: 1.408, ret loss: 0.156, fp loss: 0.467, KL loss: 28.951. 
7360000/10108000 (epoch 73) loss: 4.928, gen loss: 1.408, ret loss: 0.156, fp loss: 0.468, KL loss: 28.958. 
7370000/10108000 (epoch 73) loss: 4.927, gen loss: 1.408, ret loss: 0.156, fp loss: 0.468, KL loss: 28.952. 
Model checkpoint: save/all_data_10k_vocab/model73.ckpt. Average for epoch , loss: 4.932
7380000/10108000 (epoch 74) loss: 4.947, gen loss: 1.390, ret loss: 0.164, fp loss: 0.476, KL loss: 29.172. 
7390000/10108000 (epoch 74) loss: 4.958, gen loss: 1.420, ret loss: 0.163, fp loss: 0.475, KL loss: 29.007. 
7400000/10108000 (epoch 74) loss: 4.954, gen loss: 1.414, ret loss: 0.161, fp loss: 0.475, KL loss: 29.045. 
7410000/10108000 (epoch 74) loss: 4.949, gen loss: 1.413, ret loss: 0.161, fp loss: 0.472, KL loss: 29.030. 
7420000/10108000 (epoch 74) loss: 4.947, gen loss: 1.414, ret loss: 0.161, fp loss: 0.471, KL loss: 29.019. 
7430000/10108000 (epoch 74) loss: 4.948, gen loss: 1.417, ret loss: 0.161, fp loss: 0.469, KL loss: 29.018. 
7440000/10108000 (epoch 74) loss: 4.947, gen loss: 1.416, ret loss: 0.161, fp loss: 0.469, KL loss: 29.014. 
7450000/10108000 (epoch 74) loss: 4.948, gen loss: 1.417, ret loss: 0.161, fp loss: 0.469, KL loss: 29.015. 
7460000/10108000 (epoch 74) loss: 4.958, gen loss: 1.423, ret loss: 0.160, fp loss: 0.470, KL loss: 29.048. 
7470000/10108000 (epoch 74) loss: 4.958, gen loss: 1.422, ret loss: 0.161, fp loss: 0.470, KL loss: 29.041. 
Model checkpoint: save/all_data_10k_vocab/model74.ckpt. Average for epoch , loss: 4.959
7480000/10108000 (epoch 75) loss: 4.755, gen loss: 1.343, ret loss: 0.146, fp loss: 0.430, KL loss: 28.366. 
7490000/10108000 (epoch 75) loss: 4.946, gen loss: 1.409, ret loss: 0.164, fp loss: 0.471, KL loss: 29.008. 
7500000/10108000 (epoch 75) loss: 4.944, gen loss: 1.410, ret loss: 0.163, fp loss: 0.471, KL loss: 29.004. 
7510000/10108000 (epoch 75) loss: 4.945, gen loss: 1.411, ret loss: 0.163, fp loss: 0.471, KL loss: 29.002. 
7520000/10108000 (epoch 75) loss: 4.946, gen loss: 1.415, ret loss: 0.162, fp loss: 0.470, KL loss: 28.996. 
7530000/10108000 (epoch 75) loss: 4.940, gen loss: 1.414, ret loss: 0.161, fp loss: 0.468, KL loss: 28.975. 
7540000/10108000 (epoch 75) loss: 4.942, gen loss: 1.416, ret loss: 0.161, fp loss: 0.467, KL loss: 28.980. 
7550000/10108000 (epoch 75) loss: 4.943, gen loss: 1.415, ret loss: 0.160, fp loss: 0.469, KL loss: 28.984. 
7560000/10108000 (epoch 75) loss: 4.939, gen loss: 1.414, ret loss: 0.160, fp loss: 0.468, KL loss: 28.967. 
7570000/10108000 (epoch 75) loss: 4.937, gen loss: 1.414, ret loss: 0.159, fp loss: 0.467, KL loss: 28.963. 
7580000/10108000 (epoch 75) loss: 4.935, gen loss: 1.413, ret loss: 0.159, fp loss: 0.467, KL loss: 28.958. 
Model checkpoint: save/all_data_10k_vocab/model75.ckpt. Average for epoch , loss: 4.936
7590000/10108000 (epoch 76) loss: 4.931, gen loss: 1.414, ret loss: 0.157, fp loss: 0.464, KL loss: 28.950. 
7600000/10108000 (epoch 76) loss: 4.931, gen loss: 1.413, ret loss: 0.157, fp loss: 0.466, KL loss: 28.942. 
7610000/10108000 (epoch 76) loss: 4.923, gen loss: 1.410, ret loss: 0.158, fp loss: 0.463, KL loss: 28.923. 
7620000/10108000 (epoch 76) loss: 4.926, gen loss: 1.412, ret loss: 0.158, fp loss: 0.464, KL loss: 28.928. 
7630000/10108000 (epoch 76) loss: 4.926, gen loss: 1.413, ret loss: 0.158, fp loss: 0.463, KL loss: 28.923. 
7640000/10108000 (epoch 76) loss: 4.926, gen loss: 1.414, ret loss: 0.158, fp loss: 0.462, KL loss: 28.923. 
7650000/10108000 (epoch 76) loss: 4.921, gen loss: 1.411, ret loss: 0.157, fp loss: 0.462, KL loss: 28.916. 
7660000/10108000 (epoch 76) loss: 4.919, gen loss: 1.408, ret loss: 0.158, fp loss: 0.462, KL loss: 28.910. 
7670000/10108000 (epoch 76) loss: 4.922, gen loss: 1.411, ret loss: 0.158, fp loss: 0.462, KL loss: 28.917. 
7680000/10108000 (epoch 76) loss: 4.921, gen loss: 1.410, ret loss: 0.157, fp loss: 0.462, KL loss: 28.917. 
Model checkpoint: save/all_data_10k_vocab/model76.ckpt. Average for epoch , loss: 4.921
7690000/10108000 (epoch 77) loss: 4.959, gen loss: 1.428, ret loss: 0.157, fp loss: 0.467, KL loss: 29.067. 
7700000/10108000 (epoch 77) loss: 4.945, gen loss: 1.413, ret loss: 0.158, fp loss: 0.474, KL loss: 28.997. 
7710000/10108000 (epoch 77) loss: 4.936, gen loss: 1.410, ret loss: 0.158, fp loss: 0.470, KL loss: 28.971. 
7720000/10108000 (epoch 77) loss: 4.935, gen loss: 1.412, ret loss: 0.157, fp loss: 0.469, KL loss: 28.968. 
7730000/10108000 (epoch 77) loss: 4.934, gen loss: 1.413, ret loss: 0.157, fp loss: 0.468, KL loss: 28.963. 
7740000/10108000 (epoch 77) loss: 4.936, gen loss: 1.414, ret loss: 0.157, fp loss: 0.468, KL loss: 28.967. 
7750000/10108000 (epoch 77) loss: 4.933, gen loss: 1.413, ret loss: 0.157, fp loss: 0.468, KL loss: 28.955. 
7760000/10108000 (epoch 77) loss: 4.932, gen loss: 1.414, ret loss: 0.157, fp loss: 0.467, KL loss: 28.939. 
7770000/10108000 (epoch 77) loss: 4.933, gen loss: 1.415, ret loss: 0.157, fp loss: 0.467, KL loss: 28.938. 
7780000/10108000 (epoch 77) loss: 4.932, gen loss: 1.414, ret loss: 0.157, fp loss: 0.467, KL loss: 28.935. 
Model checkpoint: save/all_data_10k_vocab/model77.ckpt. Average for epoch , loss: 4.930
7790000/10108000 (epoch 78) loss: 4.959, gen loss: 1.433, ret loss: 0.165, fp loss: 0.461, KL loss: 28.994. 
7800000/10108000 (epoch 78) loss: 4.936, gen loss: 1.419, ret loss: 0.161, fp loss: 0.465, KL loss: 28.917. 
7810000/10108000 (epoch 78) loss: 4.933, gen loss: 1.420, ret loss: 0.160, fp loss: 0.464, KL loss: 28.893. 
7820000/10108000 (epoch 78) loss: 4.932, gen loss: 1.418, ret loss: 0.160, fp loss: 0.464, KL loss: 28.893. 
7830000/10108000 (epoch 78) loss: 4.931, gen loss: 1.417, ret loss: 0.161, fp loss: 0.464, KL loss: 28.895. 
7840000/10108000 (epoch 78) loss: 4.941, gen loss: 1.421, ret loss: 0.161, fp loss: 0.465, KL loss: 28.940. 
7850000/10108000 (epoch 78) loss: 4.940, gen loss: 1.419, ret loss: 0.161, fp loss: 0.466, KL loss: 28.946. 
7860000/10108000 (epoch 78) loss: 4.938, gen loss: 1.418, ret loss: 0.160, fp loss: 0.466, KL loss: 28.937. 
7870000/10108000 (epoch 78) loss: 4.939, gen loss: 1.419, ret loss: 0.160, fp loss: 0.466, KL loss: 28.939. 
7880000/10108000 (epoch 78) loss: 4.940, gen loss: 1.419, ret loss: 0.160, fp loss: 0.467, KL loss: 28.941. 
Model checkpoint: save/all_data_10k_vocab/model78.ckpt. Average for epoch , loss: 4.940
7890000/10108000 (epoch 79) loss: 4.914, gen loss: 1.405, ret loss: 0.158, fp loss: 0.466, KL loss: 28.853. 
7900000/10108000 (epoch 79) loss: 4.922, gen loss: 1.410, ret loss: 0.157, fp loss: 0.467, KL loss: 28.879. 
7910000/10108000 (epoch 79) loss: 4.923, gen loss: 1.409, ret loss: 0.158, fp loss: 0.467, KL loss: 28.887. 
7920000/10108000 (epoch 79) loss: 4.925, gen loss: 1.412, ret loss: 0.157, fp loss: 0.466, KL loss: 28.893. 
7930000/10108000 (epoch 79) loss: 4.933, gen loss: 1.416, ret loss: 0.158, fp loss: 0.467, KL loss: 28.917. 
7940000/10108000 (epoch 79) loss: 4.937, gen loss: 1.418, ret loss: 0.159, fp loss: 0.468, KL loss: 28.928. 
7950000/10108000 (epoch 79) loss: 4.939, gen loss: 1.420, ret loss: 0.159, fp loss: 0.467, KL loss: 28.935. 
7960000/10108000 (epoch 79) loss: 4.937, gen loss: 1.419, ret loss: 0.158, fp loss: 0.467, KL loss: 28.928. 
7970000/10108000 (epoch 79) loss: 4.935, gen loss: 1.419, ret loss: 0.158, fp loss: 0.467, KL loss: 28.923. 
7980000/10108000 (epoch 79) loss: 4.936, gen loss: 1.418, ret loss: 0.158, fp loss: 0.468, KL loss: 28.923. 
Model checkpoint: save/all_data_10k_vocab/model79.ckpt. Average for epoch , loss: 4.934
7990000/10108000 (epoch 80) loss: 4.915, gen loss: 1.397, ret loss: 0.163, fp loss: 0.464, KL loss: 28.906. 
8000000/10108000 (epoch 80) loss: 4.955, gen loss: 1.436, ret loss: 0.161, fp loss: 0.467, KL loss: 28.911. 
8010000/10108000 (epoch 80) loss: 4.966, gen loss: 1.448, ret loss: 0.159, fp loss: 0.466, KL loss: 28.930. 
8020000/10108000 (epoch 80) loss: 4.971, gen loss: 1.455, ret loss: 0.157, fp loss: 0.466, KL loss: 28.930. 
8030000/10108000 (epoch 80) loss: 4.978, gen loss: 1.461, ret loss: 0.158, fp loss: 0.466, KL loss: 28.939. 
8040000/10108000 (epoch 80) loss: 4.981, gen loss: 1.463, ret loss: 0.158, fp loss: 0.466, KL loss: 28.940. 
8050000/10108000 (epoch 80) loss: 4.980, gen loss: 1.463, ret loss: 0.157, fp loss: 0.466, KL loss: 28.937. 
8060000/10108000 (epoch 80) loss: 4.977, gen loss: 1.462, ret loss: 0.157, fp loss: 0.465, KL loss: 28.927. 
8070000/10108000 (epoch 80) loss: 4.978, gen loss: 1.463, ret loss: 0.157, fp loss: 0.465, KL loss: 28.935. 
8080000/10108000 (epoch 80) loss: 4.974, gen loss: 1.462, ret loss: 0.157, fp loss: 0.463, KL loss: 28.920. 
Model checkpoint: save/all_data_10k_vocab/model80.ckpt. Average for epoch , loss: 4.973
8090000/10108000 (epoch 81) loss: 4.932, gen loss: 1.433, ret loss: 0.160, fp loss: 0.456, KL loss: 28.828. 
8100000/10108000 (epoch 81) loss: 4.958, gen loss: 1.453, ret loss: 0.160, fp loss: 0.455, KL loss: 28.900. 
8110000/10108000 (epoch 81) loss: 4.937, gen loss: 1.436, ret loss: 0.158, fp loss: 0.455, KL loss: 28.878. 
8120000/10108000 (epoch 81) loss: 4.939, gen loss: 1.438, ret loss: 0.158, fp loss: 0.456, KL loss: 28.877. 
8130000/10108000 (epoch 81) loss: 4.937, gen loss: 1.436, ret loss: 0.158, fp loss: 0.456, KL loss: 28.878. 
8140000/10108000 (epoch 81) loss: 4.945, gen loss: 1.439, ret loss: 0.157, fp loss: 0.460, KL loss: 28.887. 
8150000/10108000 (epoch 81) loss: 4.946, gen loss: 1.440, ret loss: 0.157, fp loss: 0.460, KL loss: 28.881. 
8160000/10108000 (epoch 81) loss: 4.943, gen loss: 1.437, ret loss: 0.157, fp loss: 0.461, KL loss: 28.881. 
8170000/10108000 (epoch 81) loss: 4.942, gen loss: 1.436, ret loss: 0.157, fp loss: 0.461, KL loss: 28.879. 
8180000/10108000 (epoch 81) loss: 4.943, gen loss: 1.434, ret loss: 0.157, fp loss: 0.462, KL loss: 28.890. 
Model checkpoint: save/all_data_10k_vocab/model81.ckpt. Average for epoch , loss: 4.943
8190000/10108000 (epoch 82) loss: 4.888, gen loss: 1.400, ret loss: 0.158, fp loss: 0.458, KL loss: 28.716. 
8200000/10108000 (epoch 82) loss: 4.906, gen loss: 1.410, ret loss: 0.158, fp loss: 0.456, KL loss: 28.813. 
8210000/10108000 (epoch 82) loss: 4.913, gen loss: 1.408, ret loss: 0.160, fp loss: 0.460, KL loss: 28.855. 
8220000/10108000 (epoch 82) loss: 4.939, gen loss: 1.420, ret loss: 0.161, fp loss: 0.468, KL loss: 28.901. 
8230000/10108000 (epoch 82) loss: 4.933, gen loss: 1.417, ret loss: 0.160, fp loss: 0.467, KL loss: 28.898. 
8240000/10108000 (epoch 82) loss: 4.932, gen loss: 1.416, ret loss: 0.160, fp loss: 0.466, KL loss: 28.893. 
8250000/10108000 (epoch 82) loss: 4.929, gen loss: 1.416, ret loss: 0.160, fp loss: 0.465, KL loss: 28.886. 
8260000/10108000 (epoch 82) loss: 4.928, gen loss: 1.416, ret loss: 0.160, fp loss: 0.464, KL loss: 28.886. 
8270000/10108000 (epoch 82) loss: 4.929, gen loss: 1.417, ret loss: 0.160, fp loss: 0.463, KL loss: 28.888. 
8280000/10108000 (epoch 82) loss: 4.929, gen loss: 1.417, ret loss: 0.160, fp loss: 0.463, KL loss: 28.890. 
Model checkpoint: save/all_data_10k_vocab/model82.ckpt. Average for epoch , loss: 4.930
8290000/10108000 (epoch 83) loss: 4.961, gen loss: 1.434, ret loss: 0.166, fp loss: 0.467, KL loss: 28.940. 
8300000/10108000 (epoch 83) loss: 4.967, gen loss: 1.433, ret loss: 0.164, fp loss: 0.473, KL loss: 28.966. 
8310000/10108000 (epoch 83) loss: 4.966, gen loss: 1.436, ret loss: 0.162, fp loss: 0.472, KL loss: 28.957. 
8320000/10108000 (epoch 83) loss: 4.957, gen loss: 1.431, ret loss: 0.161, fp loss: 0.472, KL loss: 28.929. 
8330000/10108000 (epoch 83) loss: 4.959, gen loss: 1.432, ret loss: 0.161, fp loss: 0.471, KL loss: 28.946. 
8340000/10108000 (epoch 83) loss: 4.960, gen loss: 1.431, ret loss: 0.162, fp loss: 0.472, KL loss: 28.946. 
8350000/10108000 (epoch 83) loss: 4.955, gen loss: 1.429, ret loss: 0.162, fp loss: 0.470, KL loss: 28.943. 
8360000/10108000 (epoch 83) loss: 4.955, gen loss: 1.428, ret loss: 0.161, fp loss: 0.471, KL loss: 28.940. 
8370000/10108000 (epoch 83) loss: 4.958, gen loss: 1.430, ret loss: 0.161, fp loss: 0.472, KL loss: 28.948. 
8380000/10108000 (epoch 83) loss: 4.960, gen loss: 1.432, ret loss: 0.161, fp loss: 0.472, KL loss: 28.947. 
Model checkpoint: save/all_data_10k_vocab/model83.ckpt. Average for epoch , loss: 4.959
8390000/10108000 (epoch 84) loss: 4.904, gen loss: 1.406, ret loss: 0.154, fp loss: 0.480, KL loss: 28.632. 
8400000/10108000 (epoch 84) loss: 4.949, gen loss: 1.440, ret loss: 0.157, fp loss: 0.466, KL loss: 28.858. 
8410000/10108000 (epoch 84) loss: 4.943, gen loss: 1.429, ret loss: 0.158, fp loss: 0.469, KL loss: 28.873. 
8420000/10108000 (epoch 84) loss: 4.941, gen loss: 1.425, ret loss: 0.159, fp loss: 0.469, KL loss: 28.867. 
8430000/10108000 (epoch 84) loss: 4.942, gen loss: 1.428, ret loss: 0.159, fp loss: 0.467, KL loss: 28.882. 
8440000/10108000 (epoch 84) loss: 4.946, gen loss: 1.430, ret loss: 0.159, fp loss: 0.468, KL loss: 28.889. 
8450000/10108000 (epoch 84) loss: 4.944, gen loss: 1.429, ret loss: 0.159, fp loss: 0.467, KL loss: 28.884. 
8460000/10108000 (epoch 84) loss: 4.944, gen loss: 1.428, ret loss: 0.159, fp loss: 0.468, KL loss: 28.887. 
8470000/10108000 (epoch 84) loss: 4.945, gen loss: 1.430, ret loss: 0.159, fp loss: 0.468, KL loss: 28.889. 
8480000/10108000 (epoch 84) loss: 4.948, gen loss: 1.430, ret loss: 0.159, fp loss: 0.469, KL loss: 28.896. 
8490000/10108000 (epoch 84) loss: 4.947, gen loss: 1.429, ret loss: 0.159, fp loss: 0.469, KL loss: 28.897. 
Model checkpoint: save/all_data_10k_vocab/model84.ckpt. Average for epoch , loss: 4.946
8500000/10108000 (epoch 85) loss: 4.985, gen loss: 1.440, ret loss: 0.163, fp loss: 0.481, KL loss: 29.016. 
8510000/10108000 (epoch 85) loss: 4.970, gen loss: 1.429, ret loss: 0.163, fp loss: 0.479, KL loss: 28.985. 
8520000/10108000 (epoch 85) loss: 4.957, gen loss: 1.425, ret loss: 0.162, fp loss: 0.475, KL loss: 28.951. 
8530000/10108000 (epoch 85) loss: 4.954, gen loss: 1.424, ret loss: 0.162, fp loss: 0.474, KL loss: 28.938. 
8540000/10108000 (epoch 85) loss: 4.957, gen loss: 1.426, ret loss: 0.162, fp loss: 0.475, KL loss: 28.942. 
8550000/10108000 (epoch 85) loss: 4.954, gen loss: 1.426, ret loss: 0.161, fp loss: 0.474, KL loss: 28.943. 
8560000/10108000 (epoch 85) loss: 4.955, gen loss: 1.425, ret loss: 0.161, fp loss: 0.474, KL loss: 28.951. 
8570000/10108000 (epoch 85) loss: 4.957, gen loss: 1.425, ret loss: 0.161, fp loss: 0.475, KL loss: 28.959. 
8580000/10108000 (epoch 85) loss: 4.955, gen loss: 1.425, ret loss: 0.160, fp loss: 0.475, KL loss: 28.950. 
8590000/10108000 (epoch 85) loss: 4.959, gen loss: 1.428, ret loss: 0.160, fp loss: 0.475, KL loss: 28.954. 
Model checkpoint: save/all_data_10k_vocab/model85.ckpt. Average for epoch , loss: 4.958
8600000/10108000 (epoch 86) loss: 4.961, gen loss: 1.428, ret loss: 0.162, fp loss: 0.475, KL loss: 28.963. 
8610000/10108000 (epoch 86) loss: 4.966, gen loss: 1.432, ret loss: 0.160, fp loss: 0.475, KL loss: 28.982. 
8620000/10108000 (epoch 86) loss: 4.954, gen loss: 1.428, ret loss: 0.159, fp loss: 0.473, KL loss: 28.940. 
8630000/10108000 (epoch 86) loss: 4.955, gen loss: 1.430, ret loss: 0.159, fp loss: 0.473, KL loss: 28.931. 
8640000/10108000 (epoch 86) loss: 4.955, gen loss: 1.431, ret loss: 0.159, fp loss: 0.473, KL loss: 28.916. 
8650000/10108000 (epoch 86) loss: 4.959, gen loss: 1.435, ret loss: 0.159, fp loss: 0.473, KL loss: 28.926. 
8660000/10108000 (epoch 86) loss: 4.956, gen loss: 1.432, ret loss: 0.159, fp loss: 0.473, KL loss: 28.915. 
8670000/10108000 (epoch 86) loss: 4.957, gen loss: 1.433, ret loss: 0.159, fp loss: 0.473, KL loss: 28.912. 
8680000/10108000 (epoch 86) loss: 4.957, gen loss: 1.435, ret loss: 0.158, fp loss: 0.473, KL loss: 28.910. 
8690000/10108000 (epoch 86) loss: 4.958, gen loss: 1.435, ret loss: 0.159, fp loss: 0.473, KL loss: 28.916. 
Model checkpoint: save/all_data_10k_vocab/model86.ckpt. Average for epoch , loss: 4.960
8700000/10108000 (epoch 87) loss: 4.957, gen loss: 1.440, ret loss: 0.156, fp loss: 0.475, KL loss: 28.859. 
8710000/10108000 (epoch 87) loss: 4.965, gen loss: 1.434, ret loss: 0.157, fp loss: 0.479, KL loss: 28.938. 
8720000/10108000 (epoch 87) loss: 4.974, gen loss: 1.440, ret loss: 0.158, fp loss: 0.480, KL loss: 28.954. 
8730000/10108000 (epoch 87) loss: 4.978, gen loss: 1.447, ret loss: 0.158, fp loss: 0.479, KL loss: 28.942. 
8740000/10108000 (epoch 87) loss: 4.981, gen loss: 1.448, ret loss: 0.158, fp loss: 0.479, KL loss: 28.953. 
8750000/10108000 (epoch 87) loss: 4.976, gen loss: 1.447, ret loss: 0.157, fp loss: 0.478, KL loss: 28.937. 
8760000/10108000 (epoch 87) loss: 4.978, gen loss: 1.450, ret loss: 0.157, fp loss: 0.478, KL loss: 28.934. 
8770000/10108000 (epoch 87) loss: 4.976, gen loss: 1.451, ret loss: 0.157, fp loss: 0.476, KL loss: 28.922. 
8780000/10108000 (epoch 87) loss: 4.979, gen loss: 1.455, ret loss: 0.157, fp loss: 0.475, KL loss: 28.924. 
8790000/10108000 (epoch 87) loss: 4.982, gen loss: 1.455, ret loss: 0.158, fp loss: 0.476, KL loss: 28.929. 
Model checkpoint: save/all_data_10k_vocab/model87.ckpt. Average for epoch , loss: 4.981
8800000/10108000 (epoch 88) loss: 4.959, gen loss: 1.430, ret loss: 0.163, fp loss: 0.477, KL loss: 28.892. 
8810000/10108000 (epoch 88) loss: 4.959, gen loss: 1.425, ret loss: 0.164, fp loss: 0.477, KL loss: 28.933. 
8820000/10108000 (epoch 88) loss: 4.966, gen loss: 1.429, ret loss: 0.166, fp loss: 0.479, KL loss: 28.926. 
8830000/10108000 (epoch 88) loss: 4.963, gen loss: 1.427, ret loss: 0.164, fp loss: 0.479, KL loss: 28.930. 
8840000/10108000 (epoch 88) loss: 4.963, gen loss: 1.428, ret loss: 0.163, fp loss: 0.478, KL loss: 28.930. 
8850000/10108000 (epoch 88) loss: 4.966, gen loss: 1.432, ret loss: 0.163, fp loss: 0.478, KL loss: 28.936. 
8860000/10108000 (epoch 88) loss: 4.968, gen loss: 1.434, ret loss: 0.163, fp loss: 0.479, KL loss: 28.931. 
8870000/10108000 (epoch 88) loss: 4.966, gen loss: 1.432, ret loss: 0.163, fp loss: 0.479, KL loss: 28.926. 
8880000/10108000 (epoch 88) loss: 4.966, gen loss: 1.433, ret loss: 0.162, fp loss: 0.479, KL loss: 28.919. 
8890000/10108000 (epoch 88) loss: 4.969, gen loss: 1.434, ret loss: 0.163, fp loss: 0.479, KL loss: 28.934. 
Model checkpoint: save/all_data_10k_vocab/model88.ckpt. Average for epoch , loss: 4.978
8900000/10108000 (epoch 89) loss: 4.993, gen loss: 1.444, ret loss: 0.162, fp loss: 0.493, KL loss: 28.936. 
8910000/10108000 (epoch 89) loss: 4.984, gen loss: 1.436, ret loss: 0.165, fp loss: 0.492, KL loss: 28.912. 
8920000/10108000 (epoch 89) loss: 4.977, gen loss: 1.431, ret loss: 0.166, fp loss: 0.490, KL loss: 28.906. 
8930000/10108000 (epoch 89) loss: 4.974, gen loss: 1.431, ret loss: 0.164, fp loss: 0.490, KL loss: 28.894. 
8940000/10108000 (epoch 89) loss: 4.974, gen loss: 1.433, ret loss: 0.163, fp loss: 0.487, KL loss: 28.906. 
8950000/10108000 (epoch 89) loss: 4.974, gen loss: 1.435, ret loss: 0.163, fp loss: 0.486, KL loss: 28.904. 
8960000/10108000 (epoch 89) loss: 4.969, gen loss: 1.432, ret loss: 0.163, fp loss: 0.484, KL loss: 28.892. 
8970000/10108000 (epoch 89) loss: 4.966, gen loss: 1.430, ret loss: 0.163, fp loss: 0.484, KL loss: 28.893. 
8980000/10108000 (epoch 89) loss: 4.964, gen loss: 1.430, ret loss: 0.163, fp loss: 0.483, KL loss: 28.888. 
8990000/10108000 (epoch 89) loss: 4.964, gen loss: 1.431, ret loss: 0.162, fp loss: 0.482, KL loss: 28.889. 
Model checkpoint: save/all_data_10k_vocab/model89.ckpt. Average for epoch , loss: 4.964
9000000/10108000 (epoch 90) loss: 5.053, gen loss: 1.470, ret loss: 0.170, fp loss: 0.481, KL loss: 29.331. 
9010000/10108000 (epoch 90) loss: 4.997, gen loss: 1.444, ret loss: 0.165, fp loss: 0.486, KL loss: 29.025. 
9020000/10108000 (epoch 90) loss: 4.978, gen loss: 1.430, ret loss: 0.164, fp loss: 0.486, KL loss: 28.985. 
9030000/10108000 (epoch 90) loss: 4.967, gen loss: 1.424, ret loss: 0.163, fp loss: 0.483, KL loss: 28.967. 
9040000/10108000 (epoch 90) loss: 4.972, gen loss: 1.428, ret loss: 0.163, fp loss: 0.483, KL loss: 28.980. 
9050000/10108000 (epoch 90) loss: 4.973, gen loss: 1.428, ret loss: 0.163, fp loss: 0.483, KL loss: 28.987. 
9060000/10108000 (epoch 90) loss: 4.977, gen loss: 1.430, ret loss: 0.163, fp loss: 0.483, KL loss: 29.007. 
9070000/10108000 (epoch 90) loss: 4.974, gen loss: 1.430, ret loss: 0.163, fp loss: 0.483, KL loss: 28.992. 
9080000/10108000 (epoch 90) loss: 4.972, gen loss: 1.429, ret loss: 0.162, fp loss: 0.482, KL loss: 28.982. 
9090000/10108000 (epoch 90) loss: 4.971, gen loss: 1.430, ret loss: 0.162, fp loss: 0.481, KL loss: 28.974. 
Model checkpoint: save/all_data_10k_vocab/model90.ckpt. Average for epoch , loss: 4.970
9100000/10108000 (epoch 91) loss: 4.890, gen loss: 1.394, ret loss: 0.153, fp loss: 0.467, KL loss: 28.761. 
9110000/10108000 (epoch 91) loss: 4.946, gen loss: 1.423, ret loss: 0.159, fp loss: 0.475, KL loss: 28.900. 
9120000/10108000 (epoch 91) loss: 4.961, gen loss: 1.428, ret loss: 0.160, fp loss: 0.478, KL loss: 28.947. 
9130000/10108000 (epoch 91) loss: 4.961, gen loss: 1.430, ret loss: 0.161, fp loss: 0.477, KL loss: 28.932. 
9140000/10108000 (epoch 91) loss: 4.964, gen loss: 1.432, ret loss: 0.161, fp loss: 0.477, KL loss: 28.943. 
9150000/10108000 (epoch 91) loss: 4.960, gen loss: 1.431, ret loss: 0.160, fp loss: 0.476, KL loss: 28.930. 
9160000/10108000 (epoch 91) loss: 4.956, gen loss: 1.430, ret loss: 0.160, fp loss: 0.474, KL loss: 28.918. 
9170000/10108000 (epoch 91) loss: 4.956, gen loss: 1.429, ret loss: 0.160, fp loss: 0.475, KL loss: 28.916. 
9180000/10108000 (epoch 91) loss: 4.957, gen loss: 1.431, ret loss: 0.159, fp loss: 0.475, KL loss: 28.915. 
9190000/10108000 (epoch 91) loss: 4.960, gen loss: 1.433, ret loss: 0.159, fp loss: 0.474, KL loss: 28.927. 
Model checkpoint: save/all_data_10k_vocab/model91.ckpt. Average for epoch , loss: 4.959
9200000/10108000 (epoch 92) loss: 4.956, gen loss: 1.421, ret loss: 0.165, fp loss: 0.470, KL loss: 28.997. 
9210000/10108000 (epoch 92) loss: 4.956, gen loss: 1.430, ret loss: 0.161, fp loss: 0.475, KL loss: 28.895. 
9220000/10108000 (epoch 92) loss: 4.959, gen loss: 1.430, ret loss: 0.160, fp loss: 0.476, KL loss: 28.920. 
9230000/10108000 (epoch 92) loss: 4.958, gen loss: 1.433, ret loss: 0.159, fp loss: 0.475, KL loss: 28.913. 
9240000/10108000 (epoch 92) loss: 4.967, gen loss: 1.440, ret loss: 0.160, fp loss: 0.475, KL loss: 28.923. 
9250000/10108000 (epoch 92) loss: 4.963, gen loss: 1.439, ret loss: 0.160, fp loss: 0.474, KL loss: 28.901. 
9260000/10108000 (epoch 92) loss: 4.969, gen loss: 1.441, ret loss: 0.160, fp loss: 0.475, KL loss: 28.928. 
9270000/10108000 (epoch 92) loss: 4.965, gen loss: 1.438, ret loss: 0.161, fp loss: 0.473, KL loss: 28.931. 
9280000/10108000 (epoch 92) loss: 4.965, gen loss: 1.438, ret loss: 0.161, fp loss: 0.473, KL loss: 28.926. 
9290000/10108000 (epoch 92) loss: 4.965, gen loss: 1.440, ret loss: 0.160, fp loss: 0.473, KL loss: 28.923. 
Model checkpoint: save/all_data_10k_vocab/model92.ckpt. Average for epoch , loss: 4.964
9300000/10108000 (epoch 93) loss: 5.034, gen loss: 1.516, ret loss: 0.150, fp loss: 0.441, KL loss: 29.267. 
9310000/10108000 (epoch 93) loss: 4.982, gen loss: 1.455, ret loss: 0.163, fp loss: 0.468, KL loss: 28.958. 
9320000/10108000 (epoch 93) loss: 4.969, gen loss: 1.445, ret loss: 0.161, fp loss: 0.471, KL loss: 28.932. 
9330000/10108000 (epoch 93) loss: 4.967, gen loss: 1.443, ret loss: 0.160, fp loss: 0.472, KL loss: 28.918. 
9340000/10108000 (epoch 93) loss: 4.966, gen loss: 1.440, ret loss: 0.160, fp loss: 0.472, KL loss: 28.926. 
9350000/10108000 (epoch 93) loss: 4.968, gen loss: 1.441, ret loss: 0.161, fp loss: 0.473, KL loss: 28.926. 
9360000/10108000 (epoch 93) loss: 4.972, gen loss: 1.443, ret loss: 0.160, fp loss: 0.474, KL loss: 28.940. 
9370000/10108000 (epoch 93) loss: 4.979, gen loss: 1.446, ret loss: 0.161, fp loss: 0.476, KL loss: 28.960. 
9380000/10108000 (epoch 93) loss: 4.976, gen loss: 1.446, ret loss: 0.160, fp loss: 0.476, KL loss: 28.945. 
9390000/10108000 (epoch 93) loss: 4.974, gen loss: 1.445, ret loss: 0.160, fp loss: 0.475, KL loss: 28.936. 
9400000/10108000 (epoch 93) loss: 4.974, gen loss: 1.445, ret loss: 0.160, fp loss: 0.475, KL loss: 28.935. 
Model checkpoint: save/all_data_10k_vocab/model93.ckpt. Average for epoch , loss: 4.974
9410000/10108000 (epoch 94) loss: 4.967, gen loss: 1.445, ret loss: 0.163, fp loss: 0.471, KL loss: 28.888. 
9420000/10108000 (epoch 94) loss: 4.972, gen loss: 1.443, ret loss: 0.161, fp loss: 0.474, KL loss: 28.936. 
9430000/10108000 (epoch 94) loss: 4.972, gen loss: 1.445, ret loss: 0.160, fp loss: 0.473, KL loss: 28.940. 
9440000/10108000 (epoch 94) loss: 4.972, gen loss: 1.448, ret loss: 0.159, fp loss: 0.472, KL loss: 28.935. 
9450000/10108000 (epoch 94) loss: 4.972, gen loss: 1.448, ret loss: 0.159, fp loss: 0.472, KL loss: 28.922. 
9460000/10108000 (epoch 94) loss: 4.975, gen loss: 1.450, ret loss: 0.160, fp loss: 0.472, KL loss: 28.925. 
9470000/10108000 (epoch 94) loss: 4.974, gen loss: 1.449, ret loss: 0.160, fp loss: 0.472, KL loss: 28.922. 
9480000/10108000 (epoch 94) loss: 4.977, gen loss: 1.450, ret loss: 0.160, fp loss: 0.474, KL loss: 28.922. 
9490000/10108000 (epoch 94) loss: 4.974, gen loss: 1.449, ret loss: 0.161, fp loss: 0.473, KL loss: 28.913. 
9500000/10108000 (epoch 94) loss: 4.973, gen loss: 1.447, ret loss: 0.161, fp loss: 0.473, KL loss: 28.922. 
Model checkpoint: save/all_data_10k_vocab/model94.ckpt. Average for epoch , loss: 4.977
9510000/10108000 (epoch 95) loss: 4.926, gen loss: 1.403, ret loss: 0.158, fp loss: 0.476, KL loss: 28.881. 
9520000/10108000 (epoch 95) loss: 4.956, gen loss: 1.425, ret loss: 0.160, fp loss: 0.479, KL loss: 28.928. 
9530000/10108000 (epoch 95) loss: 4.963, gen loss: 1.434, ret loss: 0.160, fp loss: 0.476, KL loss: 28.926. 
9540000/10108000 (epoch 95) loss: 4.971, gen loss: 1.437, ret loss: 0.161, fp loss: 0.478, KL loss: 28.945. 
9550000/10108000 (epoch 95) loss: 4.994, gen loss: 1.446, ret loss: 0.162, fp loss: 0.484, KL loss: 29.007. 
9560000/10108000 (epoch 95) loss: 4.991, gen loss: 1.446, ret loss: 0.162, fp loss: 0.483, KL loss: 28.994. 
9570000/10108000 (epoch 95) loss: 4.986, gen loss: 1.444, ret loss: 0.162, fp loss: 0.482, KL loss: 28.976. 
9580000/10108000 (epoch 95) loss: 4.986, gen loss: 1.444, ret loss: 0.162, fp loss: 0.482, KL loss: 28.974. 
9590000/10108000 (epoch 95) loss: 4.988, gen loss: 1.445, ret loss: 0.162, fp loss: 0.482, KL loss: 28.994. 
9600000/10108000 (epoch 95) loss: 4.991, gen loss: 1.445, ret loss: 0.163, fp loss: 0.483, KL loss: 29.008. 
Model checkpoint: save/all_data_10k_vocab/model95.ckpt. Average for epoch , loss: 4.990
9610000/10108000 (epoch 96) loss: 4.942, gen loss: 1.419, ret loss: 0.163, fp loss: 0.474, KL loss: 28.865. 
9620000/10108000 (epoch 96) loss: 4.932, gen loss: 1.410, ret loss: 0.163, fp loss: 0.475, KL loss: 28.841. 
9630000/10108000 (epoch 96) loss: 4.940, gen loss: 1.415, ret loss: 0.163, fp loss: 0.475, KL loss: 28.873. 
9640000/10108000 (epoch 96) loss: 4.958, gen loss: 1.427, ret loss: 0.163, fp loss: 0.478, KL loss: 28.901. 
9650000/10108000 (epoch 96) loss: 4.967, gen loss: 1.434, ret loss: 0.163, fp loss: 0.478, KL loss: 28.920. 
9660000/10108000 (epoch 96) loss: 4.965, gen loss: 1.435, ret loss: 0.163, fp loss: 0.476, KL loss: 28.914. 
9670000/10108000 (epoch 96) loss: 4.968, gen loss: 1.438, ret loss: 0.163, fp loss: 0.476, KL loss: 28.923. 
9680000/10108000 (epoch 96) loss: 4.969, gen loss: 1.438, ret loss: 0.163, fp loss: 0.476, KL loss: 28.921. 
9690000/10108000 (epoch 96) loss: 4.967, gen loss: 1.438, ret loss: 0.162, fp loss: 0.475, KL loss: 28.913. 
9700000/10108000 (epoch 96) loss: 4.967, gen loss: 1.438, ret loss: 0.163, fp loss: 0.475, KL loss: 28.912. 
Model checkpoint: save/all_data_10k_vocab/model96.ckpt. Average for epoch , loss: 4.968
9710000/10108000 (epoch 97) loss: 5.045, gen loss: 1.483, ret loss: 0.162, fp loss: 0.486, KL loss: 29.134. 
9720000/10108000 (epoch 97) loss: 5.024, gen loss: 1.466, ret loss: 0.162, fp loss: 0.488, KL loss: 29.079. 
9730000/10108000 (epoch 97) loss: 5.006, gen loss: 1.455, ret loss: 0.162, fp loss: 0.486, KL loss: 29.030. 
9740000/10108000 (epoch 97) loss: 4.996, gen loss: 1.449, ret loss: 0.162, fp loss: 0.484, KL loss: 29.016. 
9750000/10108000 (epoch 97) loss: 5.007, gen loss: 1.458, ret loss: 0.163, fp loss: 0.483, KL loss: 29.035. 
9760000/10108000 (epoch 97) loss: 5.002, gen loss: 1.456, ret loss: 0.163, fp loss: 0.482, KL loss: 29.017. 
9770000/10108000 (epoch 97) loss: 4.998, gen loss: 1.453, ret loss: 0.162, fp loss: 0.481, KL loss: 29.014. 
9780000/10108000 (epoch 97) loss: 5.002, gen loss: 1.455, ret loss: 0.162, fp loss: 0.483, KL loss: 29.019. 
9790000/10108000 (epoch 97) loss: 5.006, gen loss: 1.457, ret loss: 0.163, fp loss: 0.484, KL loss: 29.022. 
9800000/10108000 (epoch 97) loss: 5.008, gen loss: 1.456, ret loss: 0.164, fp loss: 0.485, KL loss: 29.026. 
Model checkpoint: save/all_data_10k_vocab/model97.ckpt. Average for epoch , loss: 5.011
9810000/10108000 (epoch 98) loss: 5.044, gen loss: 1.467, ret loss: 0.166, fp loss: 0.496, KL loss: 29.143. 
9820000/10108000 (epoch 98) loss: 5.018, gen loss: 1.456, ret loss: 0.164, fp loss: 0.494, KL loss: 29.033. 
9830000/10108000 (epoch 98) loss: 5.001, gen loss: 1.445, ret loss: 0.165, fp loss: 0.492, KL loss: 28.995. 
9840000/10108000 (epoch 98) loss: 5.004, gen loss: 1.446, ret loss: 0.164, fp loss: 0.495, KL loss: 28.997. 
9850000/10108000 (epoch 98) loss: 5.012, gen loss: 1.449, ret loss: 0.165, fp loss: 0.496, KL loss: 29.011. 
9860000/10108000 (epoch 98) loss: 5.014, gen loss: 1.450, ret loss: 0.166, fp loss: 0.499, KL loss: 28.988. 
9870000/10108000 (epoch 98) loss: 5.021, gen loss: 1.455, ret loss: 0.166, fp loss: 0.499, KL loss: 29.002. 
9880000/10108000 (epoch 98) loss: 5.023, gen loss: 1.459, ret loss: 0.166, fp loss: 0.498, KL loss: 29.002. 
9890000/10108000 (epoch 98) loss: 5.020, gen loss: 1.459, ret loss: 0.165, fp loss: 0.496, KL loss: 28.997. 
9900000/10108000 (epoch 98) loss: 5.015, gen loss: 1.456, ret loss: 0.165, fp loss: 0.495, KL loss: 28.985. 
Model checkpoint: save/all_data_10k_vocab/model98.ckpt. Average for epoch , loss: 5.014
9910000/10108000 (epoch 99) loss: 4.991, gen loss: 1.448, ret loss: 0.161, fp loss: 0.494, KL loss: 28.874. 
9920000/10108000 (epoch 99) loss: 4.975, gen loss: 1.440, ret loss: 0.162, fp loss: 0.485, KL loss: 28.873. 
9930000/10108000 (epoch 99) loss: 4.979, gen loss: 1.446, ret loss: 0.161, fp loss: 0.483, KL loss: 28.899. 
9940000/10108000 (epoch 99) loss: 4.983, gen loss: 1.448, ret loss: 0.161, fp loss: 0.483, KL loss: 28.919. 
9950000/10108000 (epoch 99) loss: 4.988, gen loss: 1.452, ret loss: 0.162, fp loss: 0.482, KL loss: 28.920. 
9960000/10108000 (epoch 99) loss: 4.996, gen loss: 1.458, ret loss: 0.162, fp loss: 0.483, KL loss: 28.933. 
9970000/10108000 (epoch 99) loss: 4.997, gen loss: 1.458, ret loss: 0.162, fp loss: 0.483, KL loss: 28.938. 
9980000/10108000 (epoch 99) loss: 5.000, gen loss: 1.459, ret loss: 0.163, fp loss: 0.483, KL loss: 28.951. 
9990000/10108000 (epoch 99) loss: 4.998, gen loss: 1.459, ret loss: 0.163, fp loss: 0.482, KL loss: 28.939. 
10000000/10108000 (epoch 99) loss: 5.006, gen loss: 1.464, ret loss: 0.163, fp loss: 0.483, KL loss: 28.961. 
Model checkpoint: save/all_data_10k_vocab/model99.ckpt. Average for epoch , loss: 5.009
10010000/10108000 (epoch 100) loss: 4.992, gen loss: 1.442, ret loss: 0.169, fp loss: 0.484, KL loss: 28.964. 
10020000/10108000 (epoch 100) loss: 4.988, gen loss: 1.449, ret loss: 0.162, fp loss: 0.483, KL loss: 28.933. 
10030000/10108000 (epoch 100) loss: 5.018, gen loss: 1.457, ret loss: 0.165, fp loss: 0.492, KL loss: 29.025. 
10040000/10108000 (epoch 100) loss: 5.016, gen loss: 1.459, ret loss: 0.166, fp loss: 0.489, KL loss: 29.028. 
10050000/10108000 (epoch 100) loss: 5.015, gen loss: 1.460, ret loss: 0.166, fp loss: 0.488, KL loss: 29.016. 
10060000/10108000 (epoch 100) loss: 5.004, gen loss: 1.454, ret loss: 0.165, fp loss: 0.485, KL loss: 28.993. 
10070000/10108000 (epoch 100) loss: 4.994, gen loss: 1.449, ret loss: 0.165, fp loss: 0.482, KL loss: 28.983. 
10080000/10108000 (epoch 100) loss: 4.995, gen loss: 1.450, ret loss: 0.164, fp loss: 0.483, KL loss: 28.975. 
10090000/10108000 (epoch 100) loss: 4.992, gen loss: 1.450, ret loss: 0.164, fp loss: 0.482, KL loss: 28.962. 
10100000/10108000 (epoch 100) loss: 4.992, gen loss: 1.449, ret loss: 0.164, fp loss: 0.482, KL loss: 28.973. 
Model checkpoint: save/all_data_10k_vocab/model100.ckpt. Average for epoch , loss: 4.989
